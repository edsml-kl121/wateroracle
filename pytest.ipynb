{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/90031508/183531098-494a5819-7714-4f72-8ff8-d038982eb5f0.png\" alt=\"Water Oracle logo\"/>\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "E4IPYKT07EGj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_vhfvIvQnlU"
      },
      "source": [
        "# Manual Pytesting - overcoming permission problem and MAC M1 chip tensorflow installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0BDvI1BV_F"
      },
      "source": [
        "This Work is adapted from 'Tensorflow example workflows', \n",
        "https://developers.google.com/earth-engine/guides/tf_examples examples.\n",
        "Copyright 2020 Google LLC. https://www.apache.org/licenses/LICENSE-2.0.\n",
        "\n",
        "Please run this notebook on google colab (pro+)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"https://colab.research.google.com/drive/1ftW6WnZzVajIfZn_2A4mzmmVATQDXaud?usp=sharing\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/ese-msc-2021/irp-kl121\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
      ],
      "metadata": {
        "id": "fG64o6tE7AcL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQce4oFLBZwn"
      },
      "source": [
        "# Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0pdEYu_BXrj"
      },
      "source": [
        "## Prerequisites\n",
        "- Google account and logins\n",
        "- Google colab subscription with pro or pro+ is optional but would help with long runtime\n",
        "- Google cloud platform account in order to use google cloud bucket. (Note that you would need sufficient funds to store large amount of models and training data.)\n",
        "- Wandb.ai account which is free of charge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NTwL8SDBde9"
      },
      "source": [
        "## What is this notebook?\n",
        "\n",
        "Although, some pytests were already automatically integrated with github, namely the `config.py`, `losses.py`, `metrics_.py` some tests were not possible on the apple mac M1 machine. This is because of the tensorflow installation issue, the need to pay virtual machine to connect to google cloud bucket and authorization of the earth engine module. Hence, running pytest on google colab is suitable. Overall, the pytest is done in a both automatic and manual way\n",
        "\n",
        "In this notebook we will cover the pytest for \n",
        "- <b> `metrics_.py`</b> which requires the need to use the models.py function from tensorflow module that the Mac M1 chip cannot do.\n",
        "- <b>`preprocessing.py`</b> to test for imports of training, evaluation and testing data from the google cloud bucket. The connection to google cloud bucket is overcame by using google colab. Also, the ee permisssion...\n",
        "- <b> `config.py` </b> config.py is an important function, although it is already tested automatically, we will use config.py function throughout the problem.\n",
        "- <b> `model.py` </b> Testing the model whether it is properly training the model. It is neccesary to do the test here due to apple M1 chip incompatability with the latest tensorflow\n",
        "- <b> `sampling.py` </b> Connection to GCB requires proper authentication and logins to GCB and is much more straight forward to test in colab.\n",
        "- <b> `images.py` </b> This file involves communicating with the google cloud bucket and using the tensorflow module hence the test must be done in colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjOxf3YjDUG1"
      },
      "source": [
        "## Creating Packages\n",
        "\n",
        "Creating the tools packages that will be used throughout the notebook. The package includes \n",
        "- metrics_.py\n",
        "- config.py\n",
        "- preprocessing.py\n",
        "- sampling.py\n",
        "- losses_.py\n",
        "- images.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dM-x_AdQEzj",
        "outputId": "760df935-adb0-4d93-ec15-e1315695276f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 60\n",
            "drwxr-xr-x 2 root root  4096 Aug  7 23:17 __pycache__\n",
            "drwxr-xr-x 1 root root  4096 Aug  3 20:21 sample_data\n",
            "-rw-r--r-- 1 root root   191 Aug  7 20:20 test_blah.py\n",
            "-rw-r--r-- 1 root root 14938 Aug  7 23:16 test_images.py\n",
            "-rw-r--r-- 1 root root   494 Aug  7 18:53 test_losses_.py\n",
            "-rw-r--r-- 1 root root  4397 Aug  7 18:53 test_metrics.py\n",
            "-rw-r--r-- 1 root root  3363 Aug  7 18:53 test_model.py\n",
            "-rw-r--r-- 1 root root  4131 Aug  7 18:53 test_preprocessing.py\n",
            "-rw-r--r-- 1 root root  3725 Aug  7 18:53 test_sampling.py\n",
            "drwxr-xr-x 3 root root  4096 Aug  7 20:23 tools\n",
            "mkdir: cannot create directory ‘tools’: File exists\n",
            "total 92\n",
            "-rw-r--r-- 1 root root  2953 Aug  7 18:52 config.py\n",
            "-rw-r--r-- 1 root root  1903 Aug  7 20:26 images_extra.py\n",
            "-rw-r--r-- 1 root root 13731 Aug  7 22:23 images.py\n",
            "-rw-r--r-- 1 root root     0 Aug  7 23:21 __init__.py\n",
            "-rw-r--r-- 1 root root  1291 Aug  7 18:52 losses_.py\n",
            "-rw-r--r-- 1 root root 12985 Aug  7 18:52 metrics_.py\n",
            "-rw-r--r-- 1 root root 26634 Aug  7 18:52 model.py\n",
            "-rw-r--r-- 1 root root  6040 Aug  7 18:52 preprocessing.py\n",
            "drwxr-xr-x 2 root root  4096 Aug  7 22:28 __pycache__\n",
            "-rw-r--r-- 1 root root  4113 Aug  7 18:52 sampling.py\n"
          ]
        }
      ],
      "source": [
        "PACKAGE_PATH = 'tools'\n",
        "\n",
        "!ls -l\n",
        "!mkdir {PACKAGE_PATH}\n",
        "!touch {PACKAGE_PATH}/__init__.py\n",
        "!ls -l {PACKAGE_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {PACKAGE_PATH}/metrics_.py\n",
        "\n",
        "from keras import backend as K\n",
        "import tqdm.notebook as tq\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "CONFIG = None\n",
        "\n",
        "__all__ = [\"f1\", \"custom_accuracy\", \"MetricCalculator\", \"MetricCalculator_multiview_2\", \"MetricCalculator_multiview_3\", \"MetricCalculator_NDWI\", \"ndwi_threashold\"]\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function is used as tensorflow metrics when training. It takes in the ground truth and the\n",
        "    model predicted result and evaluate the F1 score. This is an experimental function and should not be used as\n",
        "    further model training metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : tf.tensor\n",
        "    y_pred : tf.tensor\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    F1 score in keras backend\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function is flawed because keras calculates the metrics batchwise \n",
        "    which is why F1 metric is removed from keras. To properly calulate the F1 score, we can use the callback function\n",
        "    or manually calculate F1 score after the model has finished training. The latter is chosen and this could be seen\n",
        "    in MetricCalculator, MetricCalculator_multiview_2 and MetricCalculator_multiview_3.\n",
        "  \n",
        "    The reason this function is kept is because the model was initially trained with these metrics and\n",
        "    stored in the google cloud bucket. To retrieve the models these metrics must be passed inorder to retrieve the model.\n",
        "    Since the model is optimize on the loss rather than the metrics, the incorrect metric would not effect the model\n",
        "    training process. The code is obtained/modified from:\n",
        "\n",
        "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "    https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
        "    \"\"\"\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function is used as tensorflow metrics when training. It takes in the ground truth and the\n",
        "    model predicted result and evaluate the accuracy score. This is an experimental function and should not be used as\n",
        "    further model training metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : tf.tensor\n",
        "    y_pred : tf.tensor\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    accuracy score in keras backend\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function is modified from the F1 metric above to fit the definition of accuracy. However, tensorflow's\n",
        "    \"categorical_accuracy\" is used instead. The accuracy metric would also be recalculated again in \n",
        "    MetricCalculator, MetricCalculator_multiview_2 and MetricCalculator_multiview_3.\n",
        "  \n",
        "    The reason this function is kept is because the model was initially trained with these metrics and\n",
        "    stored in the google cloud bucket. To retrieve the models these metrics must be passed inorder to retrieve the model.\n",
        "    Since the model is optimize on the loss rather than the metrics, the incorrect metric would not effect the model\n",
        "    training process. The code is obtained/modified from:\n",
        "\n",
        "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "    https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
        "    \"\"\"\n",
        "    # total_data = K.int_shape(y_true) + K.int_shape(y_pred)\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    true_negatives = K.sum(K.round(K.clip(1 - y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    total_data = - true_positives + true_negatives + possible_positives + predicted_positives\n",
        "    return (true_positives + true_negatives) / (total_data + K.epsilon())\n",
        "\n",
        "\n",
        "\n",
        "def MetricCalculator(model, test_data, total_steps):\n",
        "  \"\"\"\n",
        "  This function takes in the feature stack model loaded from google cloud bucket, the test_data which is the tensor object and\n",
        "  the number of steps and returns the metrics including accuracy, recall, precision and F1\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : keras.engine.functional.Functional\n",
        "  test_data : RepeatDataset with tf.float32\n",
        "  total_steps : int/float\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  Returns the precision, recall, f1, accuracy metric based on the model performance.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  This function should be used instead of the F1, custom_accuracy written above. The code is obtained/modified from:\n",
        "\n",
        "  https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "  https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
        "  \"\"\"\n",
        "  pred = []\n",
        "  true = []\n",
        "  pbar = tq.tqdm(total=total_steps)\n",
        "  for steps, data in enumerate(test_data):\n",
        "    # print(f'Number of steps: {steps}', end = \"\\r\")\n",
        "    pbar.update(1)\n",
        "    if steps == total_steps:\n",
        "      break\n",
        "    input = data[0]\n",
        "    y_true = data[1]\n",
        "    y_pred = np.rint(model.predict(input))\n",
        "    y_true = np.reshape(y_true, (256*256,2))\n",
        "    y_pred = np.reshape(y_pred, (256*256,2))\n",
        "    pred.append(y_pred)\n",
        "    true.append(y_true)\n",
        "\n",
        "\n",
        "  f1_macro = f1_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  recall_macro= recall_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  precision_macro = precision_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  accuracy = accuracy_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)))\n",
        "\n",
        "  print(\"precision_macro: \", precision_macro)\n",
        "  print(\"recall_macro: \", recall_macro)\n",
        "  print(\"F1_macro_Score: : \", f1_macro)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "\n",
        "  return precision_macro, recall_macro, f1_macro, accuracy\n",
        "\n",
        "\n",
        "\n",
        "def MetricCalculator_multiview_2(model, test_data, total_steps):\n",
        "  \"\"\"\n",
        "  This function takes in the multiview-2 model loaded from google cloud bucket, the test_data which is the tensor object and\n",
        "  the number of steps and returns the metrics including accuracy, recall, precision and F1\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : keras.engine.functional.Functional\n",
        "  test_data : RepeatDataset with tf.float32\n",
        "  total_steps : int/float\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  Returns the precision, recall, f1, accuracy metric based on the model performance.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  This function should be used instead of the F1, custom_accuracy written above. The code is obtained/modified from:\n",
        "\n",
        "  https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "  https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
        "  \"\"\"\n",
        "  pbar = tq.tqdm(total=total_steps)\n",
        "  pred = []\n",
        "  true = []\n",
        "  for steps, data in enumerate(test_data):\n",
        "    pbar.update(1)\n",
        "    if steps >= total_steps:\n",
        "      break\n",
        "    input = data[0]\n",
        "    x1, x2 = tf.split(input, [len(CONFIG.BANDS1),len(CONFIG.BANDS2)], 3)\n",
        "    y_true = data[1]\n",
        "    y_pred = np.rint(model.predict([x1, x2]))\n",
        "    y_true = np.reshape(y_true, (256*256,2))\n",
        "    y_pred = np.reshape(y_pred, (256*256,2))\n",
        "    pred.append(y_pred)\n",
        "    true.append(y_true)\n",
        "  f1_macro = f1_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  recall_macro= recall_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  precision_macro = precision_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  accuracy = accuracy_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)))\n",
        "\n",
        "  print(\"precision_macro: \", precision_macro)\n",
        "  print(\"recall_macro: \", recall_macro)\n",
        "  print(\"F1_macro_Score: : \", f1_macro)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "\n",
        "  return precision_macro, recall_macro, f1_macro, accuracy\n",
        "\n",
        "def MetricCalculator_multiview_3(model, test_data, total_steps):\n",
        "  \"\"\"\n",
        "  This function takes in the multiview-3 model loaded from google cloud bucket, the test_data which is the tensor object and\n",
        "  the number of steps and returns the metrics including accuracy, recall, precision and F1\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : keras.engine.functional.Functional\n",
        "  test_data : RepeatDataset with tf.float32\n",
        "  total_steps : int/float\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  Returns the precision, recall, f1, accuracy metric based on the model performance.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  This function should be used instead of the F1, custom_accuracy written above. The code is obtained/modified from:\n",
        "\n",
        "  https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "  https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
        "  \"\"\"\n",
        "  pbar = tq.tqdm(total=total_steps)\n",
        "  pred = []\n",
        "  true = []\n",
        "  for steps, data in enumerate(test_data):\n",
        "    pbar.update(1)\n",
        "    if steps >= total_steps:\n",
        "      break\n",
        "    input = data[0]\n",
        "    x1, x2, x3 = tf.split(input, [len(CONFIG.BANDS1),len(CONFIG.BANDS2),len(CONFIG.BANDS3)], 3)\n",
        "    y_true = data[1]\n",
        "    y_pred = np.rint(model.predict([x1, x2, x3]))\n",
        "    y_true = np.reshape(y_true, (256*256,2))\n",
        "    y_pred = np.reshape(y_pred, (256*256,2))\n",
        "    pred.append(y_pred)\n",
        "    true.append(y_true)\n",
        "  f1_macro = f1_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  recall_macro= recall_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  precision_macro = precision_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  accuracy = accuracy_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)))\n",
        "\n",
        "  print(\"precision_macro: \", precision_macro)\n",
        "  print(\"recall_macro: \", recall_macro)\n",
        "  print(\"F1_macro_Score: : \", f1_macro)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "\n",
        "  return precision_macro, recall_macro, f1_macro, accuracy\n",
        "\n",
        "\n",
        "def ndwi_threashold(B3, B5):\n",
        "  \"\"\"\n",
        "  This function takes in bands 3 and bands 5 from the landsat imagery and returns the tuple prediction of\n",
        "  whether there is water present or not. The threashold is set at 0.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  test_data : RepeatDataset with tf.float32\n",
        "  total_steps : int/float\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  tuple of whether there is water or not\n",
        "  \"\"\"\n",
        "  ndwi = (B3-B5)/(B3+B5)\n",
        "  if ndwi > 0:\n",
        "    return 0, 1\n",
        "  else:\n",
        "    return 1, 0\n",
        "\n",
        "def MetricCalculator_NDWI(test_data, total_steps):\n",
        "  \"\"\"\n",
        "  This function takes in the test_data which is the tensor object and\n",
        "  the number of steps and returns the metrics including accuracy, recall, precision and F1\n",
        "  for NDWI performance.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  test_data : RepeatDataset with tf.float32\n",
        "  total_steps : int/float\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  Returns the precision, recall, f1, accuracy metric based on the NDWI performance\n",
        "  \"\"\"\n",
        "  pred = []\n",
        "  true = []\n",
        "  pbar = tq.tqdm(total=total_steps)\n",
        "  for steps, data in enumerate(test_data):\n",
        "    # print(f'Number of steps: {steps}', end = \"\\r\")\n",
        "    pbar.update(1)\n",
        "    if steps == total_steps:\n",
        "      break\n",
        "    input = data[0]\n",
        "    y_true = data[1]\n",
        "    input = np.reshape(input, (256*256,2))\n",
        "    y_pred = []\n",
        "    for i in range(256*256):\n",
        "      B3, B5 = input[i]\n",
        "      first, second = ndwi_threashold(B3, B5)\n",
        "      y_pred.append([first, second])\n",
        "    y_true = np.reshape(y_true, (256*256,2))\n",
        "    y_pred = np.reshape(y_pred, (256*256,2))\n",
        "    pred.append(y_pred)\n",
        "    true.append(y_true)\n",
        "\n",
        "\n",
        "  f1_macro = f1_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  recall_macro= recall_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  precision_macro = precision_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)), average=\"macro\")\n",
        "  accuracy = accuracy_score(np.reshape(true, (total_steps*65536, 2)), np.reshape(pred, (total_steps*65536, 2)))\n",
        "\n",
        "  print(\"precision_macro: \", precision_macro)\n",
        "  print(\"recall_macro: \", recall_macro)\n",
        "  print(\"F1_macro_Score: : \", f1_macro)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "\n",
        "  return precision_macro, recall_macro, f1_macro, accuracy"
      ],
      "metadata": {
        "id": "thXHgjSP7O06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byMFKBUHPbj8",
        "outputId": "509ac7eb-d774-483f-b0ac-c846dafc618b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/metrics_.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/config.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from . import metrics_\n",
        "\n",
        "__all__ = [\"configuration\"]\n",
        "\n",
        "class configuration:\n",
        "  \"\"\"\n",
        "  In each experiment, the combinations of satellite's bands that is used to train the neural network is different.\n",
        "  Also the way to train the neural network is also different, whether it is feature stack, multiview learning with two\n",
        "  or three perceptrons. As each experiment has different settings, it is important to store them and reuse this\n",
        "  throughout the project. This class enables user to store the settings and reuse the settings.\n",
        "  \"\"\"\n",
        "  def __init__(self, PROJECT_TITLE, BANDS1, TRAIN_SIZE, EVAL_SIZE, BANDS2=[], BANDS3=[], country=\"TH\", image=None, sam_arr=None, type_=1, LOSS=\"categorical_crossentropy\", EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3):\n",
        "    \"\"\"\n",
        "\n",
        "    Initialising/storing the parameters to use later\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    PROJECT_TITLE : string\n",
        "    BANDS1 : list\n",
        "    TRAIN_SIZE : int/float\n",
        "    EVAL_SIZE : int/float\n",
        "    BANDS2 : list\n",
        "    BANDS3 : list\n",
        "    country : string\n",
        "    image : ee.image.Image\n",
        "    sam_arr : ee.image.Image\n",
        "    type : int/float\n",
        "\n",
        "    \"\"\"\n",
        "    if type_ == 1:\n",
        "      self.type_ = \"fs\"\n",
        "    elif type_ == 2:\n",
        "      self.type_ = \"m2\"\n",
        "    elif type_ == 3:\n",
        "      self.type_ = \"m3\"\n",
        "    else:\n",
        "      self.type_ = None\n",
        "    self.country = country\n",
        "    self.PROJECT_TITLE = PROJECT_TITLE\n",
        "    self.BANDS1 = BANDS1\n",
        "    self.BANDS2 = BANDS2\n",
        "    self.BANDS3 = BANDS3\n",
        "    self.BUCKET = \"geebucketwater\"\n",
        "    self.FOLDER = f'{self.type_}_{self.country}_Cnn_{self.PROJECT_TITLE}'\n",
        "    self.TRAIN_SIZE = TRAIN_SIZE\n",
        "    self.EVAL_SIZE = EVAL_SIZE\n",
        "    self.BUCKET = \"geebucketwater\"\n",
        "    self.TRAINING_BASE = f'training_patches'\n",
        "    self.EVAL_BASE = f'eval_patches'\n",
        "    self.TEST_BASE = f'test_patches'\n",
        "    self.RESPONSE = 'water'\n",
        "    self.BANDS = BANDS1 + BANDS2 + BANDS3 \n",
        "    self.FEATURES = BANDS1 + BANDS2 + BANDS3 + [self.RESPONSE]\n",
        "    # Specify the size and shape of patches expected by the model.\n",
        "    self.KERNEL_SIZE = 256\n",
        "    self.KERNEL_SHAPE = [self.KERNEL_SIZE, self.KERNEL_SIZE]\n",
        "    self.COLUMNS = [\n",
        "      tf.io.FixedLenFeature(shape=self.KERNEL_SHAPE, dtype=tf.float32) for k in self.FEATURES\n",
        "    ]\n",
        "    self.FEATURES_DICT = dict(zip(self.FEATURES, self.COLUMNS))\n",
        "    # Specify model training parameters.\n",
        "    self.BATCH_SIZE = BATCH_SIZE\n",
        "    self.EPOCHS = EPOCHS\n",
        "    self.BUFFER_SIZE = 2000\n",
        "    self.OPTIMIZER = 'adam'\n",
        "    self.LOSS = LOSS\n",
        "    self.dropout_prob = dropout_prob\n",
        "    self.METRICS = ['AUC', \"categorical_accuracy\", metrics_.f1]\n",
        "    self.image = image\n",
        "    self.sam_arr = sam_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIB7HKBEQYEG",
        "outputId": "2a5a54ff-3d71-447f-f5a0-731e1a2ee1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/preprocessing.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import ee\n",
        "\n",
        "__all__ = [\"Preprocessor\", \"maskL8sr\", \"EnsureTwodigit\", \"GenSeasonalDatesMonthly\"]\n",
        "\n",
        "class Preprocessor:\n",
        "  \"\"\"\n",
        "  Class that preprocessese and returns the training, evaluation and testing data from google cloud bucket\n",
        "  \"\"\"\n",
        "  def __init__(self, config):\n",
        "    self.config = config\n",
        "\n",
        "  def parse_tfrecord(self, example_proto):\n",
        "    \"\"\"\n",
        "    The parsing function Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  \n",
        "    Parameters\n",
        "    ----------\n",
        "    example_proto: a serialized Example\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    return tf.io.parse_single_example(example_proto, self.config.FEATURES_DICT)\n",
        "\n",
        "\n",
        "  def to_tuple(self, inputs):\n",
        "    \"\"\"\n",
        "    Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "    Parameters\n",
        "    ----------\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tuple of (inputs, outputs).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    inputsList = [inputs.get(key) for key in self.config.FEATURES]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    # Convert from CHW to HWC\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked[:,:,:len(self.config.BANDS)], tf.reshape(tf.one_hot(tf.cast(stacked[:,:,len(self.config.BANDS):], tf.int32), depth=2),[256,256,2])\n",
        "\n",
        "\n",
        "  def get_dataset(self, pattern):\n",
        "    \"\"\"\n",
        "    Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "    Get all the files matching the pattern, parse and convert to tuple.\n",
        "    Parameters\n",
        "    ----------\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.data.Dataset\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    try:\n",
        "      glob = tf.io.gfile.glob(pattern)\n",
        "    except:\n",
        "      # print(\"the bucket you specified doesn't exist\")\n",
        "      return \"the bucket you specified doesn't exist\"\n",
        "    # glob = tf.io.gfile.glob(pattern)\n",
        "    if glob == []:\n",
        "      return \"the path you specified doesn't have the data\"\n",
        "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "    dataset = dataset.map(self.parse_tfrecord, num_parallel_calls=5)\n",
        "    dataset = dataset.map(self.to_tuple, num_parallel_calls=5)\n",
        "    return dataset\n",
        "\n",
        "  def get_training_dataset(self, location):\n",
        "    \"\"\"\n",
        "    Get the preprocessed training dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    location: string\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.data.Dataset of training data.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    glob = 'gs://' + self.config.BUCKET + '/' + location + \"training_patches_\" + '*'\n",
        "    # print(glob)\n",
        "    dataset = self.get_dataset(glob)\n",
        "    dataset = dataset.shuffle(self.config.BUFFER_SIZE).batch(self.config.BATCH_SIZE).repeat()\n",
        "    return dataset\n",
        "\n",
        "  def get_training_dataset_for_testing(self, location):\n",
        "    \"\"\"\n",
        "    Get the preprocessed training dataset for testing\n",
        "    Parameters\n",
        "    ----------\n",
        "    location: string\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.data.Dataset of training data.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    glob = 'gs://' + self.config.BUCKET + '/' + location + \"training_patches_\" + '*'\n",
        "    # print(glob)\n",
        "    dataset = self.get_dataset(glob)\n",
        "    if type(dataset) == str:\n",
        "      return dataset\n",
        "    dataset = dataset.batch(1).repeat()\n",
        "    return dataset\n",
        "\n",
        "  def get_eval_dataset(self, location):\n",
        "    \"\"\"\n",
        "    Get the preprocessed evaluation dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    location: string\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.data.Dataset of evaluation data.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    glob = 'gs://' + self.config.BUCKET + '/' + location + \"eval_patches_\" + '*'\n",
        "    # print(glob)\n",
        "    dataset = self.get_dataset(glob)\n",
        "    if type(dataset) == str:\n",
        "      return dataset\n",
        "    dataset = dataset.batch(1).repeat()\n",
        "    return dataset\n",
        "\n",
        "  # print(iter(evaluation.take(1)).next())\n",
        "\n",
        "  def get_test_dataset(self, location, test_base):\n",
        "    \"\"\"\n",
        "    Get the preprocessed testing dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    location: string\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.data.Dataset of testing data.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    glob = 'gs://' + self.config.BUCKET + '/' + location + test_base + '*'\n",
        "    # print(glob)\n",
        "    dataset = self.get_dataset(glob)\n",
        "    if type(dataset) == str:\n",
        "      return dataset\n",
        "    dataset = dataset.batch(1).repeat()\n",
        "    return dataset\n",
        "\n",
        "def maskL8sr(image):\n",
        "    \"\"\"\n",
        "    Get the landsat-8 image and returned a cloud masked image\n",
        "    ----------\n",
        "    image: ee.image.Image\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A maksed landsat-8 ee.image.Image\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "    cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "    cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "    qa = image.select('pixel_qa')\n",
        "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "      qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "    return image.updateMask(mask).select(BANDS).divide(10000)\n",
        "\n",
        "\n",
        "def EnsureTwodigit(number):\n",
        "  \"\"\"\n",
        "  Transform the input month into string in the\n",
        "  correct format for date and time.\n",
        "  ----------\n",
        "  number: int\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  months in string.\n",
        "\n",
        "  \"\"\"\n",
        "  if number > 12:\n",
        "    return str(12)\n",
        "  if number < 10:\n",
        "    return \"0\"+str(number)\n",
        "  else:\n",
        "    return str(number)\n",
        "\n",
        "def GenSeasonalDatesMonthly(start, end, month_frequency = 3):\n",
        "  \"\"\"\n",
        "  Given two dictionary containing the key month and year,\n",
        "  return two arrays that contains the time between the \n",
        "  interval of start and end.\n",
        "  ----------\n",
        "  start: dict\n",
        "  end: dict\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  Two arrays containing the time elapsed between start and end\n",
        "\n",
        "  \"\"\"\n",
        "  diff_year = end[\"year\"] - start[\"year\"]\n",
        "  diff_month = end[\"month\"] - start[\"month\"]\n",
        "  starts = []\n",
        "  ends = []\n",
        "  first_data = str(start[\"year\"]) + \"-\" + EnsureTwodigit(start[\"month\"]) + \"-01\"\n",
        "  if diff_year > 0:\n",
        "    return \"please insert the same year\"\n",
        "  else:\n",
        "    for i in range(round(diff_month/month_frequency)):\n",
        "      first_data = str(start[\"year\"]) + \"-\" + EnsureTwodigit(start[\"month\"] + month_frequency * i) + \"-01\"\n",
        "      second_data = str(start[\"year\"]) + \"-\" + EnsureTwodigit(start[\"month\"] + month_frequency * i + month_frequency) + \"-01\"\n",
        "      starts.append(first_data)\n",
        "      ends.append(second_data)\n",
        "  return starts, ends\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jGAWJgQQZ6S",
        "outputId": "ba42edf5-b398-48ca-bfe3-7bd7c00d95cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/preprocessing.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/model.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "CONFIG = None\n",
        "\n",
        "__all__ = [\"conv_block\", \"EncoderMiniBlock\", \"DecoderMiniBlock\", \"CustomModel\", \\\n",
        "    \"get_model\", \"CustomModel_multiview_2\", \"get_model_multiview_2\", \"CustomModel_multiview_3\",\\\n",
        "    \"get_model_multiview_3\", \"get_model_multiview_2_HT\"]\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "    \"\"\"\n",
        "    This is processes the tensor right after the encoder to give the center block. The function\n",
        "    takes in input tensor and number of filters and returns the next layer which is the center layer\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor : tf.float32/tf.int\n",
        "    num_filters : int/float\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    returns the next layer which is the center layer which is a tensor object\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://medium.com/geekculture/u-net-implementation-from-scratch-using-tensorflow-b4342266e406\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "    encoder = layers.BatchNormalization()(encoder)\n",
        "    encoder = layers.Activation('relu')(encoder)\n",
        "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "    encoder = layers.BatchNormalization()(encoder)\n",
        "    encoder = layers.Activation('relu')(encoder)\n",
        "    return encoder\n",
        "\n",
        "def EncoderMiniBlock(inputs, num_filters=32, dropout_prob=0.3, max_pooling=True):\n",
        "    \"\"\"\n",
        "    Encoder miniblock that will enable creation of all other encoder layers in the get_model function.\n",
        "    The function takes in inputs, number of filter, a dropout probability and max_pooling parameter. The function\n",
        "    returns the next layer and the corresponding layer which will be used in decoding later on.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor : tf.float32/tf.int\n",
        "    num_filters : int/float\n",
        "    dropout_prob : float\n",
        "    max_pooling : bool\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    The function returns the next layer and the corresponding layer which will be used in decoding later on as a\n",
        "    tensor object\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://medium.com/geekculture/u-net-implementation-from-scratch-using-tensorflow-b4342266e406\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    conv = layers.Conv2D(num_filters, \n",
        "                  3,  # filter size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal')(inputs)\n",
        "    conv = layers.Conv2D(num_filters, \n",
        "                  3,  # filter size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal')(conv)\n",
        "  \n",
        "    conv = layers.BatchNormalization()(conv, training=False)\n",
        "    if dropout_prob > 0:     \n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    \n",
        "    else:\n",
        "        next_layer = conv\n",
        "    skip_connection = conv    \n",
        "    return next_layer, skip_connection\n",
        "\n",
        "def DecoderMiniBlock(prev_layer_input, skip_layer_input, num_filters=32):\n",
        "    \"\"\"\n",
        "    Decoder miniblock will enable creation of all other decoder layers in the get_model function.\n",
        "    The function takes in the previous layer inputs, the corresponding encoder and number of filters. The function\n",
        "    returns the next layer and the corresponding layer which will be used in decoding later on.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prev_layer_input : tf.float32/tf.int\n",
        "    skip_layer_input : tf.float32/tf.int\n",
        "    num_filters : int/float\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    The function returns the next layer and the corresponding layer which will be used in decoding later on as a\n",
        "    tensor object\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://medium.com/geekculture/u-net-implementation-from-scratch-using-tensorflow-b4342266e406\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    up = layers.Conv2DTranspose(\n",
        "                 num_filters,\n",
        "                 (3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='same')(prev_layer_input)\n",
        "    merge = layers.concatenate([up, skip_layer_input], axis=3)\n",
        "    conv = layers.Conv2D(num_filters, \n",
        "                 3,  \n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='HeNormal')(merge)\n",
        "    conv = layers.Conv2D(num_filters,\n",
        "                 3, \n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='HeNormal')(conv)\n",
        "    return conv\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    This class allows us to create custom model by modifying the functions of interest including the train_step\n",
        "    test_step in order to enable the model to take in multilayered inputs. Also, the execution is switched from\n",
        "    eager to graph in order to increase the speed of training\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "\n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        This function is a standard train_step in tensorflow, but graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        \"\"\"\n",
        "        This function is a standard test_step in tensorflow, but graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False)\n",
        "        # Updates the metrics tracking the loss\n",
        "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    This function puts all the previous mini encoders, decoder and conv_block and the modified custom model\n",
        "    together in order to compile and return a customized model for feature stack method.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "\n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=[None, None, len(CONFIG.BANDS)]) # 256\n",
        "    encoder0_pool, encoder0 = EncoderMiniBlock(inputs, 32) # 128\n",
        "    encoder1_pool, encoder1 = EncoderMiniBlock(encoder0_pool, 64) # 64\n",
        "    encoder2_pool, encoder2 = EncoderMiniBlock(encoder1_pool, 128) # 32\n",
        "    encoder3_pool, encoder3 = EncoderMiniBlock(encoder2_pool, 256) # 16\n",
        "    encoder4_pool, encoder4 = EncoderMiniBlock(encoder3_pool, 512) # 8\n",
        "    center = conv_block(encoder4_pool, 1024) # center\n",
        "    decoder4 = DecoderMiniBlock(center, encoder4, 512) # 16\n",
        "    decoder3 = DecoderMiniBlock(decoder4, encoder3, 256) # 32\n",
        "    decoder2 = DecoderMiniBlock(decoder3, encoder2, 128) # 64\n",
        "    decoder1 = DecoderMiniBlock(decoder2, encoder1, 64) # 128\n",
        "    decoder0 = DecoderMiniBlock(decoder1, encoder0, 32) # 256\n",
        "    outputs = layers.Dense(2, activation=tf.nn.softmax)(decoder0)\n",
        "\n",
        "    model_custom = CustomModel(inputs, outputs)\n",
        "\n",
        "    model_custom.compile(\n",
        "    optimizer=optimizers.get(CONFIG.OPTIMIZER), \n",
        "    loss=losses.get(CONFIG.LOSS),\n",
        "    metrics=[CONFIG.METRICS])\n",
        "    return model_custom\n",
        "\n",
        "class CustomModel_multiview_2(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    This class allows us to create custom model by modifying the functions of interest including the train_step\n",
        "    test_step in order to enable the model to take in 2 layer inputs for multiview learning. Also, the execution is switched from\n",
        "    eager to graph in order to increase the speed of training\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "\n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        This function modifies the standard train_step in tensorflow in order to manipulate and split the\n",
        "        input data to put into the multiview deep learning model, and graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "        x1, x2 = tf.split(x, [len(CONFIG.BANDS1),len(CONFIG.BANDS2)], 3)\n",
        "        # print(x.numpy())\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self([x1, x2], training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        \"\"\"\n",
        "        This function modifies the standard test_step in tensorflow in order to manipulate and split the\n",
        "        input data to put into the multiview deep learning model, and graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        x1, x2 = tf.split(x, [len(CONFIG.BANDS1),len(CONFIG.BANDS2)], 3)\n",
        "        # Compute predictions\n",
        "        y_pred = self([x1,x2], training=False)\n",
        "        # Updates the metrics tracking the loss\n",
        "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "def get_model_multiview_2():\n",
        "    \"\"\"\n",
        "    This function puts all the previous mini encoders, decoder and conv_block and the modified custom model\n",
        "    together in order to compile and return a customized model for multiview learning with 2 inputs\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "    \n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    first_input = layers.Input(shape=[None, None, len(CONFIG.BANDS1)]) # 256\n",
        "    first_encoder0_pool, first_encoder0 = EncoderMiniBlock(first_input, 32) # 128\n",
        "    first_encoder1_pool, first_encoder1 = EncoderMiniBlock(first_encoder0_pool, 64) # 64\n",
        "    first_encoder2_pool, first_encoder2 = EncoderMiniBlock(first_encoder1_pool, 128) # 32\n",
        "    first_encoder3_pool, first_encoder3 = EncoderMiniBlock(first_encoder2_pool, 256) # 16\n",
        "    first_encoder4_pool, first_encoder4 = EncoderMiniBlock(first_encoder3_pool, 512) # 8\n",
        "    first_center = conv_block(first_encoder4_pool, 1024) # center\n",
        "    first_decoder4 = DecoderMiniBlock(first_center, first_encoder4, 512) # 16\n",
        "    first_decoder3 = DecoderMiniBlock(first_decoder4, first_encoder3, 256) # 32\n",
        "    first_decoder2 = DecoderMiniBlock(first_decoder3, first_encoder2, 128) # 64\n",
        "    first_decoder1 = DecoderMiniBlock(first_decoder2, first_encoder1, 64) # 128\n",
        "    first_decoder0 = DecoderMiniBlock(first_decoder1, first_encoder0, 32) # 256\n",
        "\n",
        "    second_input = layers.Input(shape=[None, None, len(CONFIG.BANDS2)]) # 256\n",
        "    second_encoder0_pool, second_encoder0 = EncoderMiniBlock(second_input, 32) # 128\n",
        "    second_encoder1_pool, second_encoder1 = EncoderMiniBlock(second_encoder0_pool, 64) # 64\n",
        "    second_encoder2_pool, second_encoder2 = EncoderMiniBlock(second_encoder1_pool, 128) # 32\n",
        "    second_encoder3_pool, second_encoder3 = EncoderMiniBlock(second_encoder2_pool, 256) # 16\n",
        "    second_encoder4_pool, second_encoder4 = EncoderMiniBlock(second_encoder3_pool, 512) # 8\n",
        "    second_center = conv_block(second_encoder4_pool, 1024) # center\n",
        "    second_decoder4 = DecoderMiniBlock(second_center, second_encoder4, 512) # 16\n",
        "    second_decoder3 = DecoderMiniBlock(second_decoder4, second_encoder3, 256) # 32\n",
        "    second_decoder2 = DecoderMiniBlock(second_decoder3, second_encoder2, 128) # 64\n",
        "    second_decoder1 = DecoderMiniBlock(second_decoder2, second_encoder1, 64) # 128\n",
        "    second_decoder0 = DecoderMiniBlock(second_decoder1, second_encoder0, 32) # 256\n",
        "\n",
        "    #Fuse two features\n",
        "    concat_output = tf.keras.layers.concatenate([first_decoder0, second_decoder0], name='cca_output')\n",
        "    outputs = tf.keras.layers.Dense(2, activation=tf.nn.softmax)(concat_output)\n",
        "\n",
        "    model_custom = CustomModel_multiview_2([first_input, second_input], outputs)\n",
        "\n",
        "\n",
        "    model_custom.compile(\n",
        "        optimizer=optimizers.get(CONFIG.OPTIMIZER), \n",
        "        loss=losses.get(CONFIG.LOSS),\n",
        "        metrics=[CONFIG.METRICS])\n",
        "    return model_custom\n",
        "\n",
        "\n",
        "class CustomModel_multiview_3(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    This class allows us to create custom model by modifying the functions of interest including the train_step\n",
        "    test_step in order to enable the model to take in 3 layer inputs for multiview learning. Also, the execution is switched from\n",
        "    eager to graph in order to increase the speed of training\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "\n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        This function modifies the standard train_step in tensorflow in order to manipulate and split the\n",
        "        input data to put into the multiview deep learning model, and graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "        x1, x2, x3 = tf.split(x, [len(CONFIG.BANDS1),len(CONFIG.BANDS2),len(CONFIG.BANDS3)], 3)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self([x1, x2, x3], training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        \"\"\"\n",
        "        This function modifies the standard test_step in tensorflow in order to manipulate and split the\n",
        "        input data to put into the multiview deep learning model, and graph execution is used instead.\n",
        "        The function takes in the data and return the corresponding metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : tuple of tf.float32/tf.int\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        The function returns the corresponding metrics\n",
        "        \"\"\"\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        x1, x2, x3 = tf.split(x, [len(CONFIG.BANDS1),len(CONFIG.BANDS2),len(CONFIG.BANDS3)], 3)\n",
        "        # Compute predictions\n",
        "        y_pred = self([x1,x2,x3], training=False)\n",
        "        # Updates the metrics tracking the loss\n",
        "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "def get_model_multiview_3():\n",
        "    \"\"\"\n",
        "    This function puts all the previous mini encoders, decoder and conv_block and the modified custom model\n",
        "    together in order to compile and return a customized model for multiview learning with 3 inputs\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "\n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    first_input = layers.Input(shape=[None, None, len(CONFIG.BANDS1)]) # 256\n",
        "    first_encoder0_pool, first_encoder0 = EncoderMiniBlock(first_input, 32) # 128\n",
        "    first_encoder1_pool, first_encoder1 = EncoderMiniBlock(first_encoder0_pool, 64) # 64\n",
        "    first_encoder2_pool, first_encoder2 = EncoderMiniBlock(first_encoder1_pool, 128) # 32\n",
        "    first_encoder3_pool, first_encoder3 = EncoderMiniBlock(first_encoder2_pool, 256) # 16\n",
        "    first_encoder4_pool, first_encoder4 = EncoderMiniBlock(first_encoder3_pool, 512) # 8\n",
        "    first_center = conv_block(first_encoder4_pool, 1024) # center\n",
        "    first_decoder4 = DecoderMiniBlock(first_center, first_encoder4, 512) # 16\n",
        "    first_decoder3 = DecoderMiniBlock(first_decoder4, first_encoder3, 256) # 32\n",
        "    first_decoder2 = DecoderMiniBlock(first_decoder3, first_encoder2, 128) # 64\n",
        "    first_decoder1 = DecoderMiniBlock(first_decoder2, first_encoder1, 64) # 128\n",
        "    first_decoder0 = DecoderMiniBlock(first_decoder1, first_encoder0, 32) # 256\n",
        "\n",
        "    second_input = layers.Input(shape=[None, None, len(CONFIG.BANDS2)]) # 256\n",
        "    second_encoder0_pool, second_encoder0 = EncoderMiniBlock(second_input, 32) # 128\n",
        "    second_encoder1_pool, second_encoder1 = EncoderMiniBlock(second_encoder0_pool, 64) # 64\n",
        "    second_encoder2_pool, second_encoder2 = EncoderMiniBlock(second_encoder1_pool, 128) # 32\n",
        "    second_encoder3_pool, second_encoder3 = EncoderMiniBlock(second_encoder2_pool, 256) # 16\n",
        "    second_encoder4_pool, second_encoder4 = EncoderMiniBlock(second_encoder3_pool, 512) # 8\n",
        "    second_center = conv_block(second_encoder4_pool, 1024) # center\n",
        "    second_decoder4 = DecoderMiniBlock(second_center, second_encoder4, 512) # 16\n",
        "    second_decoder3 = DecoderMiniBlock(second_decoder4, second_encoder3, 256) # 32\n",
        "    second_decoder2 = DecoderMiniBlock(second_decoder3, second_encoder2, 128) # 64\n",
        "    second_decoder1 = DecoderMiniBlock(second_decoder2, second_encoder1, 64) # 128\n",
        "    second_decoder0 = DecoderMiniBlock(second_decoder1, second_encoder0, 32) # 256\n",
        "\n",
        "    third_input = layers.Input(shape=[None, None, len(CONFIG.BANDS3)]) # 256\n",
        "    third_encoder0_pool, third_encoder0 = EncoderMiniBlock(third_input, 32) # 128\n",
        "    third_encoder1_pool, third_encoder1 = EncoderMiniBlock(third_encoder0_pool, 64) # 64\n",
        "    third_encoder2_pool, third_encoder2 = EncoderMiniBlock(third_encoder1_pool, 128) # 32\n",
        "    third_encoder3_pool, third_encoder3 = EncoderMiniBlock(third_encoder2_pool, 256) # 16\n",
        "    third_encoder4_pool, third_encoder4 = EncoderMiniBlock(third_encoder3_pool, 512) # 8\n",
        "    third_center = conv_block(third_encoder4_pool, 1024) # center\n",
        "    third_decoder4 = DecoderMiniBlock(third_center, third_encoder4, 512) # 16\n",
        "    third_decoder3 = DecoderMiniBlock(third_decoder4, third_encoder3, 256) # 32\n",
        "    third_decoder2 = DecoderMiniBlock(third_decoder3, third_encoder2, 128) # 64\n",
        "    third_decoder1 = DecoderMiniBlock(third_decoder2, third_encoder1, 64) # 128\n",
        "    third_decoder0 = DecoderMiniBlock(third_decoder1, third_encoder0, 32) # 256\n",
        "\n",
        "    #Fuse two features\n",
        "    concat_output = tf.keras.layers.concatenate([first_decoder0, second_decoder0, third_decoder0], name='cca_output')\n",
        "    outputs = tf.keras.layers.Dense(2, activation=tf.nn.softmax)(concat_output)\n",
        "\n",
        "    model_custom = CustomModel_multiview_3([first_input, second_input, third_input], outputs)\n",
        "\n",
        "\n",
        "    model_custom.compile(\n",
        "        optimizer=optimizers.get(CONFIG.OPTIMIZER), \n",
        "        loss=losses.get(CONFIG.LOSS),\n",
        "        metrics=[CONFIG.METRICS])\n",
        "    return model_custom\n",
        "\n",
        "\n",
        "\n",
        "def get_model_multiview_2_HT():\n",
        "    \"\"\"\n",
        "    This function puts all the previous mini encoders, decoder and conv_block and the modified custom model\n",
        "    together in order to compile and return a customized model for multiview learning with 2 inputs. This function\n",
        "    is also used in hyperparameter tuning for loss functions and dropouts rate.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is%20a%20powerful,they%20occur%20in%20your%20code.\n",
        "    \n",
        "    https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "    \"\"\"\n",
        "    first_input = layers.Input(shape=[None, None, len(CONFIG.BANDS1)]) # 256\n",
        "    first_encoder0_pool, first_encoder0 = EncoderMiniBlock(first_input, 32, dropout_prob = CONFIG.dropout_prob) # 128\n",
        "    first_encoder1_pool, first_encoder1 = EncoderMiniBlock(first_encoder0_pool, 64, dropout_prob = CONFIG.dropout_prob) # 64\n",
        "    first_encoder2_pool, first_encoder2 = EncoderMiniBlock(first_encoder1_pool, 128, dropout_prob = CONFIG.dropout_prob) # 32\n",
        "    first_encoder3_pool, first_encoder3 = EncoderMiniBlock(first_encoder2_pool, 256, dropout_prob = CONFIG.dropout_prob) # 16\n",
        "    first_encoder4_pool, first_encoder4 = EncoderMiniBlock(first_encoder3_pool, 512, dropout_prob = CONFIG.dropout_prob) # 8\n",
        "    first_center = conv_block(first_encoder4_pool, 1024) # center\n",
        "    first_decoder4 = DecoderMiniBlock(first_center, first_encoder4, 512) # 16\n",
        "    first_decoder3 = DecoderMiniBlock(first_decoder4, first_encoder3, 256) # 32\n",
        "    first_decoder2 = DecoderMiniBlock(first_decoder3, first_encoder2, 128) # 64\n",
        "    first_decoder1 = DecoderMiniBlock(first_decoder2, first_encoder1, 64) # 128\n",
        "    first_decoder0 = DecoderMiniBlock(first_decoder1, first_encoder0, 32) # 256\n",
        "\n",
        "    second_input = layers.Input(shape=[None, None, len(CONFIG.BANDS2)]) # 256\n",
        "    second_encoder0_pool, second_encoder0 = EncoderMiniBlock(second_input, 32) # 128\n",
        "    second_encoder1_pool, second_encoder1 = EncoderMiniBlock(second_encoder0_pool, 64) # 64\n",
        "    second_encoder2_pool, second_encoder2 = EncoderMiniBlock(second_encoder1_pool, 128) # 32\n",
        "    second_encoder3_pool, second_encoder3 = EncoderMiniBlock(second_encoder2_pool, 256) # 16\n",
        "    second_encoder4_pool, second_encoder4 = EncoderMiniBlock(second_encoder3_pool, 512) # 8\n",
        "    second_center = conv_block(second_encoder4_pool, 1024) # center\n",
        "    second_decoder4 = DecoderMiniBlock(second_center, second_encoder4, 512) # 16\n",
        "    second_decoder3 = DecoderMiniBlock(second_decoder4, second_encoder3, 256) # 32\n",
        "    second_decoder2 = DecoderMiniBlock(second_decoder3, second_encoder2, 128) # 64\n",
        "    second_decoder1 = DecoderMiniBlock(second_decoder2, second_encoder1, 64) # 128\n",
        "    second_decoder0 = DecoderMiniBlock(second_decoder1, second_encoder0, 32) # 256\n",
        "\n",
        "    #Fuse two features\n",
        "    concat_output = tf.keras.layers.concatenate([first_decoder0, second_decoder0], name='cca_output')\n",
        "    outputs = tf.keras.layers.Dense(2, activation=tf.nn.softmax)(concat_output)\n",
        "\n",
        "    model_custom = CustomModel_multiview_2([first_input, second_input], outputs)\n",
        "\n",
        "\n",
        "    model_custom.compile(\n",
        "        optimizer=optimizers.get(CONFIG.OPTIMIZER), \n",
        "        loss=CONFIG.LOSS,\n",
        "        metrics=[CONFIG.METRICS])\n",
        "    return model_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9wy-RE-Qjoj",
        "outputId": "b076b56e-785e-4805-859f-b6320016164f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/sampling.py\n",
        "\n",
        "import ee\n",
        "\n",
        "__all__ = [\"Training_task\", \"Eval_task\", \"Testing_task\"]\n",
        "\n",
        "def Training_task(trainingPolys, n, N, arrays, setting, foldername):\n",
        "  \"\"\"\n",
        "  Exporting Training data to google cloud bucket\n",
        "  Parameters\n",
        "  ----------\n",
        "  trainingPolys : ee.featurecollection.FeatureCollection\n",
        "  n : int/float\n",
        "  N : int/float\n",
        "  arrays: ee.image.Image\n",
        "  setting: tools.config.configuration\n",
        "  foldername : string\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.data.Dataset of testing data.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "  # Export all the training data (in many pieces), ith one task \n",
        "  # per geometry.\n",
        "  for g in range(trainingPolys.size().getInfo()):\n",
        "    geomSample = ee.FeatureCollection([])\n",
        "    for i in range(n):\n",
        "      sample = arrays.sample(\n",
        "        region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
        "        scale = 30,\n",
        "        numPixels = N / n, # Size of the shard.\n",
        "        seed = i,\n",
        "        tileScale = 8\n",
        "      )\n",
        "      geomSample = geomSample.merge(sample)\n",
        "    \n",
        "    desc = setting.TRAINING_BASE + '_g' + str(g)\n",
        "    task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection = geomSample,\n",
        "      description = desc,\n",
        "      bucket = setting.BUCKET,\n",
        "      fileNamePrefix = foldername + '/' + desc,\n",
        "      fileFormat = 'TFRecord',\n",
        "      selectors = setting.BANDS + [setting.RESPONSE]\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "\n",
        "def Eval_task(evalPolys, n, N, arrays, setting, foldername):\n",
        "  \"\"\"\n",
        "  Exporting Evaluating data to google cloud bucket\n",
        "  Parameters\n",
        "  ----------\n",
        "  evalPolys : ee.featurecollection.FeatureCollection\n",
        "  n : int/float\n",
        "  N : int/float\n",
        "  arrays: ee.image.Image\n",
        "  setting: tools.config.configuration\n",
        "  foldername : string\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.data.Dataset of testing data.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  evalPolysList = evalPolys.toList(evalPolys.size())\n",
        "  # Export all the evaluation data.\n",
        "  for g in range(evalPolys.size().getInfo()):\n",
        "    geomSample = ee.FeatureCollection([])\n",
        "    for i in range(n):\n",
        "      sample = arrays.sample(\n",
        "        region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
        "        scale = 30,\n",
        "        numPixels = N / n,\n",
        "        seed = i,\n",
        "        tileScale = 8\n",
        "      )\n",
        "      geomSample = geomSample.merge(sample)\n",
        "\n",
        "    desc = setting.EVAL_BASE + '_g' + str(g)\n",
        "    task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection = geomSample,\n",
        "      description = desc,\n",
        "      bucket = setting.BUCKET,\n",
        "      fileNamePrefix = foldername + '/' + desc,\n",
        "      fileFormat = 'TFRecord',\n",
        "      selectors = setting.BANDS + [setting.RESPONSE]\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "\n",
        "def Testing_task(testPolys, n, N, arrays, setting, foldername, Test_base):\n",
        "  \"\"\"\n",
        "  Exporting Testing data to google cloud bucket\n",
        "  Parameters\n",
        "  ----------\n",
        "  testPolys : ee.featurecollection.FeatureCollection\n",
        "  n : int/float\n",
        "  N : int/float\n",
        "  arrays: ee.image.Image\n",
        "  setting: tools.config.configuration\n",
        "  foldername : string\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.data.Dataset of testing data.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  # Export all the test data.\n",
        "  testPolysList = testPolys.toList(testPolys.size())\n",
        "  for g in range(testPolys.size().getInfo()):\n",
        "    geomSample = ee.FeatureCollection([])\n",
        "    for i in range(n):\n",
        "      sample = arrays.sample(\n",
        "        region = ee.Feature(testPolysList.get(g)).geometry(), \n",
        "        scale = 30,\n",
        "        numPixels = N / n,\n",
        "        seed = i,\n",
        "        tileScale = 8\n",
        "      )\n",
        "      geomSample = geomSample.merge(sample)\n",
        "\n",
        "    desc = Test_base + '_g' + str(g)\n",
        "    task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection = geomSample,\n",
        "      description = desc,\n",
        "      bucket = setting.BUCKET,\n",
        "      fileNamePrefix = foldername + '/' + desc,\n",
        "      fileFormat = 'TFRecord',\n",
        "      selectors = setting.BANDS + [setting.RESPONSE]\n",
        "    )\n",
        "    task.start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqIRjwQXqwjG",
        "outputId": "3cd3ae55-350e-4855-f95f-cf0407f6d118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/sampling.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/losses_.py\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "\n",
        "__all__ = [\"dice_coef\", \"dice_p_cc\"]\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Recieve the true and predicted tensor and return the resulting dice loss\n",
        "    to prevent overfitting.\n",
        "    ----------\n",
        "    y_true: tf.float32\n",
        "    y_pred: tf.float32\n",
        "    smooth: int/float\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.float32 with same dimension as input tf.float32\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://www.kaggle.com/code/kmader/u-net-with-dice-and-augmentation/notebook\n",
        "    \"\"\"\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "\n",
        "\n",
        "def dice_p_cc(in_gt, in_pred):\n",
        "    \"\"\"\n",
        "    Recieve the true and predicted tensor and return the resulting categorical dice loss\n",
        "    ----------\n",
        "    in_gt: tf.float32\n",
        "    in_pred: tf.float32\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tf.float32 with same dimension as input tf.float32\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://www.kaggle.com/code/kmader/u-net-with-dice-and-augmentation/notebook\n",
        "    \"\"\"\n",
        "    return categorical_crossentropy(in_gt, in_pred) - K.log(dice_coef(in_gt, in_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-9ZJM-j7nfm",
        "outputId": "96364ae4-27e6-4984-a294-0a4879638345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/losses_.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PACKAGE_PATH}/images.py\n",
        "\n",
        "import json\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import tqdm.notebook as tq\n",
        "import tensorflow as tf\n",
        "import ee\n",
        "import subprocess\n",
        "import ast\n",
        "\n",
        "\n",
        "__all__ = [\"doExport\", \"predictionSingleinput\", \"predictionMultipleinput\", \"predictionMultipleinput_3\", \\\n",
        "           \"uploadToGEEAsset\", \"LoadImage\", \"doPrediction_featurestack\", \\\n",
        "            \"doPrediction_multiview_2\", \"doPrediction_multiview_3\"]\n",
        "\n",
        "\n",
        "def doExport(out_image_base, kernel_buffer, region, setting, extra_folder= \"\"):\n",
        "  \"\"\"\n",
        "  Export the image with features and area of interest\n",
        "  to google cloud bucket. The function doesn't exit until\n",
        "  the task is complete. The optional extra_folder arguement lets you put\n",
        "  the exported tf.record.gz in a folder\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  out_image_base : string\n",
        "  kernel_buffer : list\n",
        "  region : ee.Geometry.BBox\n",
        "  setting : dict\n",
        "  extra_folder : string\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  if extra_folder == \"\":\n",
        "    fileNamePrefix_ = setting.FOLDER + '/' + out_image_base\n",
        "  else:\n",
        "    fileNamePrefix_ = setting.FOLDER + '/' + extra_folder + '/' + out_image_base\n",
        "  task = ee.batch.Export.image.toCloudStorage(\n",
        "    image = setting.image.select(setting.BANDS),\n",
        "    description = out_image_base,\n",
        "    bucket = setting.BUCKET,\n",
        "    fileNamePrefix = fileNamePrefix_,\n",
        "    region = region.getInfo()['coordinates'],\n",
        "    scale = 30,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e10,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': setting.KERNEL_SHAPE,\n",
        "      'kernelSize': kernel_buffer,\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Cloud Storage...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')\n",
        "\n",
        "\n",
        "def LoadImage(out_image_base, user_folder, kernel_buffer, setting, extra_folder = \"\"):\n",
        "  \"\"\"\n",
        "  Load the image from the google cloud bucket and preprocess the image for prediction\n",
        "  and provide crutial information for exporting to GEE asset\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  out_image_base : string\n",
        "  user_folder : string\n",
        "  kernel_buffer : list\n",
        "  setting : dict\n",
        "  extra_folder : string\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  imageDataset as tensor data for prediction, patches as int, x_buffer as int, y_buffer as int, jsonFile as string\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # Get a list of all the files in the output bucket.\n",
        "  if extra_folder == \"\":\n",
        "    process = subprocess.run([\"gsutil\", \"ls\", f'gs://{setting.BUCKET}/{setting.FOLDER}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    filesList = process.stdout.split('\\n')\n",
        "  else:\n",
        "    process = subprocess.run([\"gsutil\", \"ls\", f'gs://{setting.BUCKET}/{setting.FOLDER}/{extra_folder}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    filesList = process.stdout.split('\\n')\n",
        "\n",
        "  print(filesList)\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
        "  print(exportFilesList)\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "  if jsonFile == None:\n",
        "    return \"image path doesn't exist\"\n",
        "\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  process = subprocess.run([\"gsutil\", \"cat\", f'{jsonFile}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "  jsonText = process.stdout\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  # mixer = json.loads(jsonText.nlstr)\n",
        "  mixer = ast.literal_eval(jsonText)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(kernel_buffer[0] / 2)\n",
        "  y_buffer = int(kernel_buffer[1] / 2)\n",
        "\n",
        "  buffered_shape = [\n",
        "      setting.KERNEL_SHAPE[0] + kernel_buffer[0],\n",
        "      setting.KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n",
        "      for k in setting.BANDS\n",
        "  ]\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    \"\"\"\n",
        "    The parsing function Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    example_proto: a serialized Example\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    \"\"\"\n",
        "    Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "    Parameters\n",
        "    ----------\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A tuple of (inputs, outputs).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The code is obtained/modified from:\n",
        "\n",
        "    https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "    \"\"\"\n",
        "    inputsList = [inputs.get(key) for key in setting.BANDS]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked\n",
        "\n",
        "  imageFeaturesDict = dict(zip(setting.BANDS, imageColumns))\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "  return imageDataset, patches, x_buffer, y_buffer, jsonFile\n",
        "\n",
        "def predictionSingleinput(model, imageDataset, patches):\n",
        "  \"\"\"\n",
        "  Given the model, and image for prediction, predict the image\n",
        "  with feature stack U-Net\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : model : keras.engine.functional.Functional\n",
        "  imageDataset : tf.data.Dataset of training data (BatchDataset)\n",
        "  patches : int\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.float32 with same dimension as imageDataset\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  print('Running predictions...')\n",
        "  predictions = model.predict(imageDataset, steps=patches, verbose=1)\n",
        "  return predictions\n",
        "\n",
        "def predictionMultipleinput(model, imageDataset, patches, setting):\n",
        "  \"\"\"\n",
        "  Given the model, and image for prediction, predict the image\n",
        "  with Multi-view learning U-Net\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : model : keras.engine.functional.Functional\n",
        "  imageDataset : tf.data.Dataset of training data (BatchDataset)\n",
        "  patches : int\n",
        "  setting : dict\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.float32 with same dimension as imageDataset\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  print('Running predictions...')\n",
        "  predictions = []\n",
        "  pbar = tq.tqdm(total=patches)\n",
        "  for data in imageDataset:\n",
        "    pbar.update(1)\n",
        "    x1, x2 = tf.split(data, [len(setting.BANDS1), len(setting.BANDS2)], 3)\n",
        "    predictions.append(model.predict([x1, x2], verbose=0))\n",
        "  return predictions\n",
        "\n",
        "def predictionMultipleinput_3(model, imageDataset, patches, setting):\n",
        "  \"\"\"\n",
        "  Given the model, and image for prediction, predict the image\n",
        "  with Multi-view learning U-Net with 3 inputs\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : model : keras.engine.functional.Functional\n",
        "  imageDataset : tf.data.Dataset of training data (BatchDataset)\n",
        "  patches : int\n",
        "  setting : dict\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A tf.float32 with same dimension as imageDataset\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  print('Running predictions...')\n",
        "  predictions = []\n",
        "  pbar = tq.tqdm(total=patches)\n",
        "  for data in imageDataset:\n",
        "    pbar.update(1)\n",
        "    x1, x2, x3 = tf.split(data, [len(setting.BANDS1), len(setting.BANDS2), len(setting.BANDS3)], 3)\n",
        "    predictions.append(model.predict([x1, x2, x3], verbose=0))\n",
        "  return predictions\n",
        "\n",
        "def uploadToGEEAsset(x_buffer, y_buffer, predictions, out_image_base, jsonFile, suffix, setting, multiview=False, user_folder='users/mewchayutaphong'):\n",
        "  \"\"\"\n",
        "  Given the predictions, exported file location other information\n",
        "  on the image to be exported, return the required information\n",
        "  in order to export the predicted image to the GEE asset\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  x_buffer : int\n",
        "  y_buffer : int\n",
        "  predictions : tf.data.Dataset of training data (BatchDataset)\n",
        "  out_image_base : string\n",
        "  jsonFile : string\n",
        "  suffix : string\n",
        "  setting : dict\n",
        "  user_folder : string\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A out_image_asset a location to the output GEE asset folder\n",
        "  as a string, out_image_file of the prediction as TFRecord and the\n",
        "  corresponding json file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'gs://' + setting.BUCKET + '/' + setting.FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "  for predictionPatch in predictions:\n",
        "    if multiview == True:\n",
        "      predictionPatch = predictionPatch[0]\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+setting.KERNEL_SIZE, y_buffer:y_buffer+setting.KERNEL_SIZE]\n",
        "    predictionPatch = np.argmax(predictionPatch, -1)\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=predictionPatch.flatten()))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  writer.close()\n",
        " \n",
        "  # Start the upload.\n",
        "  out_image_asset = user_folder + '/' + out_image_base + suffix\n",
        "  # !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}\n",
        "  return out_image_asset, out_image_file, jsonFile\n",
        "\n",
        "\n",
        "def doPrediction_featurestack(out_image_base, user_folder, kernel_buffer, model, suffix, setting, extra_folder=\"\"):\n",
        "  \"\"\"\n",
        "  Putting all the image functions together. Load the Image, predict the output with featurestack U-Net, return information\n",
        "  ready to be exported to GEE asset\n",
        "  ----------\n",
        "  pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A out_image_asset a location to the output GEE asset folder\n",
        "  as a string, out_image_file of the prediction as TFRecord and the\n",
        "  corresponding json file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  output_load_image = LoadImage(out_image_base, user_folder, kernel_buffer, setting, extra_folder)\n",
        "  if type(output_load_image) == str:\n",
        "    return \"wrong file location\"\n",
        "  imageDataset, patches, x_buffer, y_buffer, jsonFile = output_load_image\n",
        "  predictions = predictionSingleinput(model, imageDataset, patches)\n",
        "  out_image_asset, out_image_file, jsonFile = uploadToGEEAsset(x_buffer, y_buffer, predictions, out_image_base, jsonFile, suffix, setting, False)\n",
        "  return out_image_asset, out_image_file, jsonFile\n",
        "\n",
        "def doPrediction_multiview_2(out_image_base, user_folder, kernel_buffer, model, suffix, setting, extra_folder=\"\"):\n",
        "  \"\"\"\n",
        "  Putting all the image functions together. Load the Image, predict the output with \n",
        "  Multi-view U-Net (2 inputs), return information ready to be exported to GEE asset\n",
        "  ----------\n",
        "  pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A out_image_asset a location to the output GEE asset folder\n",
        "  as a string, out_image_file of the prediction as TFRecord and the\n",
        "  corresponding json file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  output_load_image = LoadImage(out_image_base, user_folder, kernel_buffer, setting, extra_folder)\n",
        "  if type(output_load_image) == str:\n",
        "    return \"wrong file location\"\n",
        "  imageDataset, patches, x_buffer, y_buffer, jsonFile = output_load_image\n",
        "  predictions = predictionMultipleinput(model, imageDataset, patches, setting)\n",
        "  out_image_asset, out_image_file, jsonFile = uploadToGEEAsset(x_buffer, y_buffer, predictions, out_image_base, jsonFile, suffix, setting, True)\n",
        "  return out_image_asset, out_image_file, jsonFile\n",
        "\n",
        "def doPrediction_multiview_3(out_image_base, user_folder, kernel_buffer, model, suffix, setting, extra_folder=\"\"):\n",
        "  \"\"\"\n",
        "  Putting all the image functions together. Load the Image, predict the output with \n",
        "  Multi-view U-Net (3 inputs), return information ready to be exported to GEE asset\n",
        "  ----------\n",
        "  pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  A out_image_asset a location to the output GEE asset folder\n",
        "  as a string, out_image_file of the prediction as TFRecord and the\n",
        "  corresponding json file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The code is obtained/modified from:\n",
        "\n",
        "  https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/UNET_regression_demo.ipynb\n",
        "  \"\"\"\n",
        "  output_load_image = LoadImage(out_image_base, user_folder, kernel_buffer, setting, extra_folder)\n",
        "  if type(output_load_image) == str:\n",
        "    return \"wrong file location\"\n",
        "  imageDataset, patches, x_buffer, y_buffer, jsonFile = output_load_image\n",
        "  predictions = predictionMultipleinput_3(model, imageDataset, patches, setting)\n",
        "  out_image_asset, out_image_file, jsonFile = uploadToGEEAsset(x_buffer, y_buffer, predictions, out_image_base, jsonFile, suffix, setting, True)\n",
        "  return out_image_asset, out_image_file, jsonFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yeEP2qXQlJW"
      },
      "source": [
        "## Authentication\n",
        "\n",
        "Authentication with google colab, earth engine api and google cloud bucket is required before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IPl7xwloQR3",
        "outputId": "f6702e5d-8639-48bb-dcc8-006afdc78491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=gjwOrTSCV4nTtCGqynyRvoBVj-CmAAMrsudcMEEVXIY&tc=0JeBKWttyTpXD5beHpXlUZLOx9vMBe-l6wC-WQDKNYo&cc=asJjcdfHGARZ2XcSgzrKacYopjmNTJupRkuCAGDRtm4\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AdQt8qhPsFMi2GJxUnnX7c7Gb8tVkw9vCF-kUG6BCBJXj9fygX79t4Zv7zw\n",
            "\n",
            "Successfully saved authorization token.\n",
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "project_id = 'coastal-cell-299117'\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-pIsT0sUFqX"
      },
      "source": [
        "- Add you private key here\n",
        "- get your private key here: https://developers.google.com/earth-engine/guides/service_account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGodvARMpFix",
        "outputId": "34d41d4f-2a8b-485d-f805-314f24f75884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .private-key.json\n"
          ]
        }
      ],
      "source": [
        "%%file .private-key.json\n",
        "\n",
        "{\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"coastal-cell-299117\",\n",
        "  \"private_key_id\": \"d05dc0cf15e02bfd54f718f43821f9c1e263006a\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC+Xk4MkMIemEr2\\nt0ey0ipsIXJ0Ff/x+tKKtmRXXDxVm3G8Se7/al6XWmTFoRscnD3hoJphvn01/xqs\\nDyz0EyytqwPNOH3zJ2y7ZdkRe5Idtg/Lbbziqul4eJVn7kS2viftjUatZCHTvSOy\\na6UvxI2bHgLfxZtY2kwhpOonQ6iiKEpUIM2qrgtwmr0CU+660lZCqEjaWCcDvpry\\ntHCLVqjQk5rgCliGROR+6NKFQfB5lnV+2UxSVyxhoy+xTQDyBge5uFiWi64unNCU\\n7aE4sweJ35FHeGKQu02fz1AEsEjQMHlybGQzdK/zuroiH+58lmeSrhcLwZf7u27C\\n+HY4YHhJAgMBAAECggEAAmO3ZdW61Ay8Eyb3i81yyh7s23trtic8dZCGx6hxGu97\\nsN36NaNJiuuP7IGiUBx/c9my2mN8WZ1JQcvid/FWLBtjjbPF8/OEnEER5ZPoIH6Y\\nqehnmK5FxjT4RiDR5LvUDzmo35QMTya2gB61CPmV//KTXWjy811xG3KBHGtPXnKu\\ntLW7C9W4OGiMMvf4ZmNDUBQURjAbqmj9K3EPRbf7oCIxT9az1ehAdQPUdR98f7CM\\nuAZsbLxFZECCK2TWdK/od0g9xYIEIYDXNc9fICGM66IFUBMJctNNu40swMFR1CvZ\\nceC3mjqOWC6dWQHAZOlOdacqkL8+9cktF2gpVp8egQKBgQDxcITtGLnnfbvs8PHc\\nxh75zvKhHnRKMpocMgpvP1M3C/FlZS2n+96bXejPnaNT9kA+/QVwrUgaEbrpROjL\\nCPQ+Ws9zZzL8BQbHbyAPAXt1/v6O4d7ZDlubr2+kNB9grrWUgE77lNu9ytidi8Ci\\nDTgs75qXdFZzXDkX1xxwSnobyQKBgQDJ2VH3MIEslWNth4wLiuuMRTgN9RwKZuXX\\nbU7ft6/Hx0Hy36WrfQebUbDvveXCnnlKSK2ikW5qGhnbon+4fVIAZMwDzKVTC9Yn\\ncVIzanihyNNpS9sdfQFEXT6M6T6vaugM00F5mMCF8ah94IX+70lDZu/MVDgonrBR\\nhv3ANeC4gQKBgEnyFEQploZ30961zN25MDOCVn1SPnubE+gey2NXGb16QuyzGFCi\\nq4MaN/ueZC+K9BJWnBvudm7Fj2FyYXoNvAB8/5xwtwTI5VKfjkoKQi3Zc01/kCka\\nZKRCDwdTj2ilGafpxEb5SHPQdJeL/euj8NiSad6JGxEp5bKPh3480TlBAoGBAKDi\\nzHdXvQ5ZQHgUG2cz4o3aulQ9s40C+V5drQmassxtIT7CTp3CuaZuVbaxyQn4ILs5\\n9NRoUPbXORccjeryUMMplIfOvVPVUmv74kZDLkXd+cyq/sqhUbo5DFtqqmFNuApI\\n9J5ER+g7d05mAMfz2JSV3rshweV2nxlMnMNw7l6BAoGBAN8WD6WXTZdGt31J18VJ\\n7ckLikB2zCJRX+ekMStYXXkgW+YSK2YJzBs0ECkcEmIpOvX7ZS4XW1nJXjdFutrU\\n8Bbuwv4y46t1ahx+rz5OQKyCeKaF4oeDCjjXJRisBBQfNW8nqXRlDaDspQdisDlX\\nSqk6a/3uJ9/xabhNHiskbs86\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"geeimp@coastal-cell-299117.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"118281239934168975167\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/geeimp%40coastal-cell-299117.iam.gserviceaccount.com\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDpmE2hTDanl"
      },
      "source": [
        "## Import other required library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQaQbZObVsy0"
      },
      "outputs": [],
      "source": [
        "!pip -q install pytest pytest-sugar\n",
        "from importlib import reload\n",
        "import tensorflow as tf\n",
        "import folium\n",
        "from pprint import pprint\n",
        "reload(images) # Uncomment this line to rerun the modified packages\n",
        "from tools import preprocessing, config, metrics_, model, losses_, images\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ssPpI8D5nm"
      },
      "source": [
        "# Pytest\n",
        "\n",
        "The test is broken down into\n",
        "\n",
        "- <b>`metrics_.py`</b> whilst using `model.py` and `config.py`\n",
        "- <b>`preprocessing.py`</b> whilst using `config.py`\n",
        "- <b>`model.py`</b> whilst using `config.py`\n",
        "- <b>`lossses_.py`</b>\n",
        "- <b>`sampling.py`</b> whilst using config.py and preprocessing.py\n",
        "\n",
        "Followed by a compilation cell at the end. Please execute the compilation cell to see the pytest results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VmpehShCyBz"
      },
      "source": [
        "## Testing the <b>`metrics_.py`</b> whilst using `model.py` and `config.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpmVeL24Q_vB",
        "outputId": "a7d22da5-1bb7-404a-a2bb-77dc6dde4a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_metrics.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_metrics.py\n",
        "\n",
        "from tensorflow.keras import losses\n",
        "import pytest\n",
        "import math\n",
        "from tools import preprocessing, config, metrics_, model\n",
        "import tensorflow as tf\n",
        "\n",
        "train_size = 1\n",
        "eval_size = 1\n",
        "configs = {}\n",
        "configs[\"L8SR\"] = config.configuration(\"L8SR\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, country = \"global\")\n",
        "configs[\"L8SR_el_sl_as\"] = config.configuration(\"L8SR_el_sl_as\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"elevation\", \"slope\", \"aspect\"], type_=2, country = \"global\")\n",
        "configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country = \"global\")\n",
        "configs[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                 , TRAIN_SIZE= train_size, EVAL_SIZE = eval_size\\\n",
        "                                                 , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "\n",
        "test_data = [(tf.random.uniform(shape=(1,256,256,6)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m2 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m3 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m2_hp = [(tf.random.uniform(shape=(1,256,256,10)), tf.zeros(shape=(1,256,256,2)))]\n",
        "\n",
        "\n",
        "@pytest.fixture(params=[test_data])\n",
        "def data(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_(request):\n",
        "    return request.param\n",
        "\n",
        "def test_Metrics(data, totalsteps_):\n",
        "    model.CONFIG = configs[\"L8SR\"]\n",
        "    dummymodel = model.get_model()\n",
        "    precision_macro, recall_macro, f1_macro, accuracy = metrics_.MetricCalculator(dummymodel, data, totalsteps_)\n",
        "    assert precision_macro <= 0 or precision_macro >= 1\n",
        "    assert recall_macro <= 0 or precision_macro >= 1\n",
        "    assert f1_macro <= 0 or precision_macro >= 1\n",
        "    assert accuracy <= 0 or precision_macro >= 1\n",
        "\n",
        "@pytest.fixture(params=[test_data_m2])\n",
        "def data_m2(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_m2(request):\n",
        "    return request.param\n",
        "\n",
        "def test_Metrics_2(data_m2, totalsteps_m2):\n",
        "    model.CONFIG = configs[\"L8SR_el_sl_as\"]\n",
        "    metrics_.CONFIG = configs[\"L8SR_el_sl_as\"]\n",
        "    print(model.CONFIG.BANDS1, model.CONFIG.BANDS2)\n",
        "    dummymodel_multiview_2 = model.get_model_multiview_2()\n",
        "    precision_macro, recall_macro, f1_macro, accuracy = metrics_.MetricCalculator_multiview_2(dummymodel_multiview_2, data_m2, totalsteps_m2)\n",
        "    assert precision_macro <= 0 or precision_macro >= 1\n",
        "    assert recall_macro <= 0 or precision_macro >= 1\n",
        "    assert f1_macro <= 0 or precision_macro >= 1\n",
        "    assert accuracy <= 0 or precision_macro >= 1\n",
        "\n",
        "@pytest.fixture(params=[test_data_m3])\n",
        "def data_m3(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_m3(request):\n",
        "    return request.param\n",
        "\n",
        "def test_Metrics_3(data_m3, totalsteps_m3):\n",
        "    model.CONFIG = configs[\"L8SR_S1_as3\"]\n",
        "    metrics_.CONFIG = configs[\"L8SR_S1_as3\"]\n",
        "    print(model.CONFIG.BANDS1, model.CONFIG.BANDS2)\n",
        "    dummymodel_multiview_3 = model.get_model_multiview_3()\n",
        "    precision_macro, recall_macro, f1_macro, accuracy = metrics_.MetricCalculator_multiview_3(dummymodel_multiview_3, data_m3, totalsteps_m3)\n",
        "    assert precision_macro <= 0 or precision_macro >= 1\n",
        "    assert recall_macro <= 0 or precision_macro >= 1\n",
        "    assert f1_macro <= 0 or precision_macro >= 1\n",
        "    assert accuracy <= 0 or precision_macro >= 1\n",
        "\n",
        "@pytest.fixture(params=[test_data_m2_hp])\n",
        "def data_m2_hp(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_m2_hp(request):\n",
        "    return request.param\n",
        "\n",
        "def test_Metrics_2_hp(data_m2_hp, totalsteps_m2_hp):\n",
        "    model.CONFIG = configs[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "    metrics_.CONFIG = configs[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "    print(model.CONFIG.BANDS1, model.CONFIG.BANDS2)\n",
        "    dummymodel_multiview_2_HT = model.get_model_multiview_2_HT()\n",
        "    precision_macro, recall_macro, f1_macro, accuracy = metrics_.MetricCalculator_multiview_2(dummymodel_multiview_2_HT, data_m2_hp, totalsteps_m2_hp)\n",
        "    assert precision_macro <= 0 or precision_macro >= 1\n",
        "    assert recall_macro <= 0 or precision_macro >= 1\n",
        "    assert f1_macro <= 0 or precision_macro >= 1\n",
        "    assert accuracy <= 0 or precision_macro >= 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVV57fvAC1ZI"
      },
      "source": [
        "## Testing <b>`preprocessing.py`</b> whilst using `config.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiC8lUFTkn3p",
        "outputId": "f18e97d6-92dc-468b-f193-a3b0fd4c6ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_preprocessing.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_preprocessing.py\n",
        "\n",
        "import pytest\n",
        "import math\n",
        "from tools import preprocessing, config\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import ee\n",
        "import json\n",
        "import base64\n",
        "import os\n",
        "import tools.preprocessing as preprocessing\n",
        "import pytest\n",
        "\n",
        "# connection to the service account\n",
        "service_account = 'geeimp@coastal-cell-299117.iam.gserviceaccount.com'\n",
        "credentials = ee.ServiceAccountCredentials(service_account, '.private-key.json')\n",
        "ee.Initialize(credentials)\n",
        "\n",
        "train_size = 1\n",
        "eval_size = 1\n",
        "configs = {}\n",
        "configs[\"L8SR\"] = config.configuration(\"L8SR\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, country = \"global\")\n",
        "configs[\"L8SR_el_sl_as\"] = config.configuration(\"L8SR_el_sl_as\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"elevation\", \"slope\", \"aspect\"], type_=2, country = \"global\")\n",
        "configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country = \"global\")\n",
        "\n",
        "def test_masking():\n",
        "  l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2018-01-01','2018-02-01')\n",
        "  L8SR = l8sr.map(preprocessing.maskL8sr).median()\n",
        "  l8srBands = l8sr.median().bandNames().getInfo()\n",
        "  L8SRmaskedBands = L8SR.bandNames().getInfo()\n",
        "  assert l8srBands == ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11', 'sr_aerosol', 'pixel_qa', 'radsat_qa']\n",
        "  assert L8SRmaskedBands == ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "\n",
        "def test_preprocessing():\n",
        "    conf = configs[\"L8SR\"]\n",
        "    preproc = preprocessing.Preprocessor(conf)\n",
        "    evaluation = preproc.get_eval_dataset(\"train_in_global/\")\n",
        "    if type(evaluation) == str:\n",
        "      assert evaluation == \"the path you specified doesn't have the data\" or evaluation == \"the bucket you specified doesn't exist\"\n",
        "    else:\n",
        "      first_evaluation = iter(evaluation.take(1)).next()\n",
        "      assert (np.array(tf.shape(first_evaluation[0])) == np.array([1,256,256,6])).all()\n",
        "      assert (np.array(tf.shape(first_evaluation[1])) == np.array([1,256,256,2])).all()\n",
        "\n",
        "\n",
        "def test_preprocessing_m2():\n",
        "    conf = configs[\"L8SR_el_sl_as\"]\n",
        "    preproc = preprocessing.Preprocessor(conf)\n",
        "    evaluation = preproc.get_eval_dataset(\"train_in_global/\")\n",
        "    if type(evaluation) == str:\n",
        "      assert evaluation == \"the path you specified doesn't have the data\" or evaluation == \"the bucket you specified doesn't exist\"\n",
        "    else:\n",
        "      first_evaluation = iter(evaluation.take(1)).next()\n",
        "      assert (np.array(tf.shape(first_evaluation[0])) == np.array([1,256,256,9])).all()\n",
        "      assert (np.array(tf.shape(first_evaluation[1])) == np.array([1,256,256,2])).all()\n",
        "\n",
        "\n",
        "def test_preprocessing_m3():\n",
        "    conf = configs[\"L8SR_S1_as3\"]\n",
        "    preproc = preprocessing.Preprocessor(conf)\n",
        "    evaluation = preproc.get_eval_dataset(\"train_in_global/\")\n",
        "    if type(evaluation) == str:\n",
        "      assert evaluation == \"the path you specified doesn't have the data\" or evaluation == \"the bucket you specified doesn't exist\"\n",
        "    else:\n",
        "      first_evaluation = iter(evaluation.take(1)).next()\n",
        "      assert (np.array(tf.shape(first_evaluation[0])) == np.array([1,256,256,9])).all()\n",
        "      assert (np.array(tf.shape(first_evaluation[1])) == np.array([1,256,256,2])).all()\n",
        "\n",
        "def test_non_existingfile():\n",
        "    configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country=\"global\")\n",
        "    conf = configs[\"L8SR_S1_as3\"]\n",
        "    preproc = preprocessing.Preprocessor(conf)\n",
        "    evaluation = preproc.get_eval_dataset(\"train_in_globalk/\")\n",
        "    assert evaluation == \"the path you specified doesn't have the data\" or evaluation == \"the bucket you specified doesn't exist\"\n",
        "\n",
        "def test_wrong_bucket():\n",
        "    configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country=\"global\")\n",
        "    conf = configs[\"L8SR_S1_as3\"]\n",
        "    conf.BUCKET = \"asd\"\n",
        "    preproc = preprocessing.Preprocessor(conf)\n",
        "    evaluation = preproc.get_eval_dataset(\"train_in_globalk/\")\n",
        "    assert evaluation == \"the path you specified doesn't have the data\" or evaluation == \"the bucket you specified doesn't exist\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjiJbgOFTmjK"
      },
      "source": [
        "## Testing <b>`model.py`</b> whilst using `config.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaCzkR79ToQn",
        "outputId": "46b8c684-6bd9-4478-df73-33b951dd0439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_model.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_model.py\n",
        "\n",
        "from tensorflow.keras import losses\n",
        "import pytest\n",
        "import math\n",
        "from tools import config, model\n",
        "import tensorflow as tf\n",
        "\n",
        "train_size = 1\n",
        "eval_size = 1\n",
        "configs = {}\n",
        "configs[\"L8SR\"] = config.configuration(\"L8SR\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, country = \"global\")\n",
        "configs[\"L8SR_el_sl_as\"] = config.configuration(\"L8SR_el_sl_as\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"elevation\", \"slope\", \"aspect\"], type_=2, country = \"global\")\n",
        "configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country = \"global\")\n",
        "configs[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                 , TRAIN_SIZE= train_size, EVAL_SIZE = eval_size\\\n",
        "                                                 , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "\n",
        "test_data = [(tf.random.uniform(shape=(1,256,256,6)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m2 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m3 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m2_hp = [(tf.random.uniform(shape=(1,256,256,10)), tf.zeros(shape=(1,256,256,2)))]\n",
        "\n",
        "\n",
        "@pytest.fixture(params=[test_data])\n",
        "def data(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_(request):\n",
        "    return request.param\n",
        "\n",
        "def test_model_FS(data, totalsteps_):\n",
        "    model.CONFIG = configs[\"L8SR\"]\n",
        "    dummymodel = model.get_model()\n",
        "    prediction_shape = dummymodel.predict(data[0][0]).shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "@pytest.fixture(params=[test_data_m2])\n",
        "def data_m2(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_(request):\n",
        "    return request.param\n",
        "\n",
        "def test_model_M2(data_m2, totalsteps_):\n",
        "    model.CONFIG = configs[\"L8SR_el_sl_as\"]\n",
        "    dummymodel = model.get_model_multiview_2()\n",
        "    x1, x2 = tf.split(data_m2[0][0], [len(model.CONFIG.BANDS1), len(model.CONFIG.BANDS2)], 3)\n",
        "    prediction_shape = dummymodel.predict([x1, x2]).shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "@pytest.fixture(params=[test_data_m3])\n",
        "def data_m3(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_(request):\n",
        "    return request.param\n",
        "\n",
        "def test_model_M3(data_m3, totalsteps_):\n",
        "    model.CONFIG = configs[\"L8SR_S1_as3\"]\n",
        "    dummymodel = model.get_model_multiview_2()\n",
        "    x1, x2, x3 = tf.split(data_m3[0][0], [len(model.CONFIG.BANDS1), len(model.CONFIG.BANDS2), len(model.CONFIG.BANDS3)], 3)\n",
        "    prediction_shape = dummymodel.predict([x1, x2]).shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "@pytest.fixture(params=[test_data_m2_hp])\n",
        "def data_m2_hp(request):\n",
        "    return request.param\n",
        "\n",
        "@pytest.fixture(params=[1])\n",
        "def totalsteps_(request):\n",
        "    return request.param\n",
        "\n",
        "def test_model_M2_HT(data_m2_hp, totalsteps_):\n",
        "    model.CONFIG = configs[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "    dummymodel = model.get_model_multiview_2_HT()\n",
        "    x1, x2 = tf.split(data_m2_hp[0][0], [len(model.CONFIG.BANDS1), len(model.CONFIG.BANDS2)], 3)\n",
        "    prediction_shape = dummymodel.predict([x1, x2]).shape\n",
        "    assert prediction_shape == (1,256,256,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMlkyyIS7VK-"
      },
      "source": [
        "## Testing `losses_.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypg249AJ7UVc",
        "outputId": "b1a18417-9fa6-45f4-f04b-9079864793a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_losses_.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_losses_.py\n",
        "\n",
        "import tools.losses_ as losses_\n",
        "import pytest\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "test_data = [tf.ones(shape=(1,256,256,2)), tf.ones(shape=(1,256,256,2))]\n",
        "\n",
        "def test_dicecc():\n",
        "    loss = losses_.dice_p_cc(test_data[0], test_data[1])\n",
        "    assert np.isclose(float(tf.math.reduce_mean(loss)), 1.3862922191619873)\n",
        "\n",
        "def test_dice():\n",
        "    loss = losses_.dice_coef(test_data[0], test_data[1])\n",
        "    print(float(tf.math.reduce_mean(loss)))\n",
        "    assert np.isclose(float(tf.math.reduce_mean(loss)), 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgf72uPUZ_Y3"
      },
      "source": [
        "## Testing `sampling.py` whilst using `config.py` and `preprocessing.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6bnCR9waDK4",
        "outputId": "5db19c5c-9740-48a3-cbc3-274905489920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_sampling.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_sampling.py\n",
        "\n",
        "import pytest\n",
        "import math\n",
        "from tools import sampling, config, preprocessing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import ee\n",
        "import time\n",
        "\n",
        "# connection to the service account\n",
        "service_account = 'geeimp@coastal-cell-299117.iam.gserviceaccount.com'\n",
        "credentials = ee.ServiceAccountCredentials(service_account, '.private-key.json')\n",
        "ee.Initialize(credentials)\n",
        "\n",
        "# Sentinel-1 Data (10m)\n",
        "S1 = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
        "        .filterDate('2018-01-01','2018-02-01') \\\n",
        "\n",
        "S1A = S1.median()\n",
        "S1 = S1.select('VV', 'VH').median()\n",
        "\n",
        "# USG’s Landsat-8 Collection 1 and Tier 1 (30m)\n",
        "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2018-01-01','2018-02-01')\n",
        "\n",
        "# Cloud masking function.\n",
        "L8SR = l8sr.map(preprocessing.maskL8sr).median()\n",
        "\n",
        "# NASADEM: NASA NASADEM Digital Elevation (30m)\n",
        "elevation = ee.Image('NASA/NASADEM_HGT/001').select('elevation');\n",
        "slope = ee.Terrain.slope(elevation);\n",
        "aspect = ee.Terrain.aspect(elevation);\n",
        "\n",
        "# JRC-Monthly Water history (30m)\n",
        "waterdata = ee.ImageCollection('JRC/GSW1_3/MonthlyHistory').filterDate('2018-01-01', '2018-02-01').median()\n",
        "watermask = waterdata.select(\"water\")\n",
        "mask = watermask.gt(0) # masking out \"no data\" region\n",
        "maskedComposite = waterdata.updateMask(mask).subtract(1) # Shifting the labels to make it binary\n",
        "train_size = 720\n",
        "eval_size = 72*3\n",
        "configs = {}\n",
        "configs[\"L8SR\"] = config.configuration(\"L8SR\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, country = \"global\")\n",
        "configs[\"L8SR_el_sl_as\"] = config.configuration(\"L8SR_el_sl_as\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"elevation\", \"slope\", \"aspect\"], type_=2, country = \"global\")\n",
        "configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country = \"global\")\n",
        "configs[\"L8SR\"].image = L8SR.float()\n",
        "configs[\"L8SR_el_sl_as\"].image = ee.Image.cat([L8SR, elevation, slope, aspect]).float()\n",
        "configs[\"L8SR_S1_as3\"].image = ee.Image.cat([L8SR, S1, aspect])\n",
        "\n",
        "\n",
        "India_eval = ee.Geometry.BBox(75.68466076783874, 21.263314014804795, 78.04672131471374, 22.770654917923526)\n",
        "Tibet_eval = ee.Geometry.BBox(93.92188430197075, 26.847874650118836, 95.93238234884575, 28.356873608833094)\n",
        "brazil_eval = ee.Geometry.BBox(-53.749924908880686, -22.833543783979856, -51.047288190130686, -20.999024800255494)\n",
        "\n",
        "evalPolys_global = ee.FeatureCollection(Tibet_eval).merge(India_eval).merge(brazil_eval)\n",
        "\n",
        "for key in list(configs):\n",
        "  settings = configs[key]\n",
        "  featureStack = ee.Image.cat([\n",
        "  settings.image.select(settings.BANDS),\n",
        "  maskedComposite.select(settings.RESPONSE)\n",
        "  ]).float()\n",
        "  list_ = ee.List.repeat(1, settings.KERNEL_SIZE)\n",
        "  lists = ee.List.repeat(list_, settings.KERNEL_SIZE)\n",
        "  kernel = ee.Kernel.fixed(settings.KERNEL_SIZE, settings.KERNEL_SIZE, lists)\n",
        "  arrays = featureStack.neighborhoodToArray(kernel)\n",
        "  configs[key].sam_arr = arrays\n",
        "  print(key, settings.sam_arr.getInfo())\n",
        "\n",
        "def test_wrong_bucket():\n",
        "    conf = configs[\"L8SR_S1_as3\"]\n",
        "    conf.BUCKET = \"asd\"\n",
        "    foldername = \"wrongbucket\"\n",
        "    n = 1 # Number of shards in each polygon.\n",
        "    N = 1 # Total sample size in each polygon.\n",
        "    sampling.Eval_task(evalPolys_global, n, N, conf.sam_arr, conf, foldername)\n",
        "    while ee.data.listOperations()[0]['metadata']['state'] == 'PENDING':\n",
        "      time.sleep(3)\n",
        "    if ee.data.listOperations()[2]['metadata']['state'] == 'COMPLETED':\n",
        "      message = 'Image export completed.'\n",
        "    elif ee.data.listOperations()[2]['metadata']['state'] == 'FAILED':\n",
        "      message = 'Error with image export.'\n",
        "    print(message)\n",
        "    assert message == 'Error with image export.'\n",
        "    # assert message == 'Image export completed.'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1OfI6rzR0aG"
      },
      "source": [
        "## Testing images.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLc4vQtIR3QK",
        "outputId": "88336b91-d7fc-40a1-f533-e16a1caddc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_images.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_images.py\n",
        "#!usr/bin/bash python\n",
        "import subprocess\n",
        "subprocess.run([\"gsutil\", \"ls\", 'gs://geebucketwater/train_in_global'])\n",
        "\n",
        "import pytest\n",
        "import math\n",
        "from tools import images, config, preprocessing, model, metrics_, losses_\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import ee\n",
        "import time\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "# connection to the service account\n",
        "service_account = 'geeimp@coastal-cell-299117.iam.gserviceaccount.com'\n",
        "credentials = ee.ServiceAccountCredentials(service_account, '.private-key.json')\n",
        "ee.Initialize(credentials)\n",
        "\n",
        "# Sentinel-1 Data (10m)\n",
        "S1 = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
        "        .filterDate('2018-01-01','2018-02-01') \\\n",
        "\n",
        "S1A = S1.median()\n",
        "S1 = S1.select('VV', 'VH').median()\n",
        "\n",
        "# USG’s Landsat-8 Collection 1 and Tier 1 (30m)\n",
        "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2018-01-01','2018-02-01')\n",
        "\n",
        "# Cloud masking function.\n",
        "L8SR = l8sr.map(preprocessing.maskL8sr).median()\n",
        "\n",
        "# NASADEM: NASA NASADEM Digital Elevation (30m)\n",
        "elevation = ee.Image('NASA/NASADEM_HGT/001').select('elevation');\n",
        "slope = ee.Terrain.slope(elevation);\n",
        "aspect = ee.Terrain.aspect(elevation);\n",
        "\n",
        "test_data = [(tf.random.uniform(shape=(1,256,256,6)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m2 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "test_data_m3 = [(tf.random.uniform(shape=(1,256,256,9)), tf.zeros(shape=(1,256,256,2)))]\n",
        "\n",
        "# # JRC-Monthly Water history (30m)\n",
        "# waterdata = ee.ImageCollection('JRC/GSW1_3/MonthlyHistory').filterDate('2018-01-01', '2018-02-01').median()\n",
        "# watermask = waterdata.select(\"water\")\n",
        "# mask = watermask.gt(0) # masking out \"no data\" region\n",
        "# maskedComposite = waterdata.updateMask(mask).subtract(1) # Shifting the labels to make it binary\n",
        "train_size = 720\n",
        "eval_size = 72*3\n",
        "configs = {}\n",
        "configs[\"L8SR\"] = config.configuration(\"L8SR\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, country = \"global\")\n",
        "configs[\"L8SR_el_sl_as\"] = config.configuration(\"L8SR_el_sl_as\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"elevation\", \"slope\", \"aspect\"], type_=2, country = \"global\")\n",
        "configs[\"L8SR_S1_as3\"] = config.configuration(\"L8SR_S1_as3\", [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], train_size, eval_size, [\"VV\", \"VH\"], [\"aspect\"], type_=3, country = \"global\")\n",
        "configs[\"L8SR\"].image = L8SR.float()\n",
        "configs[\"L8SR_el_sl_as\"].image = ee.Image.cat([L8SR, elevation, slope, aspect]).float()\n",
        "configs[\"L8SR_S1_as3\"].image = ee.Image.cat([L8SR, S1, aspect])\n",
        "\n",
        "\n",
        "tb_region = ee.Geometry.BBox(94.72188430197075, 28.047874650118836, 94.93238234884575, 28.356873608833094)\n",
        "tb_image_base = f'Tibet_with_Multi_seasonalEXP_'\n",
        "kernel_buffer = [128, 128]\n",
        "\n",
        "def test_pred_single_input():\n",
        "    model.CONFIG = configs[\"L8SR\"]\n",
        "    dummymodel = model.get_model()\n",
        "    prediction_shape = images.predictionSingleinput(dummymodel, test_data[0][0], 1).shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "def test_pred_multi_input():\n",
        "    model.CONFIG = configs[\"L8SR_el_sl_as\"]\n",
        "    dummymodel = model.get_model_multiview_2()\n",
        "    prediction_shape = images.predictionMultipleinput(dummymodel, [test_data_m2[0][0]], 1, configs[\"L8SR_el_sl_as\"])[0].shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "\n",
        "def test_pred_multi_input_3():\n",
        "    model.CONFIG = configs[\"L8SR_S1_as3\"]\n",
        "    dummymodel = model.get_model_multiview_3()\n",
        "    prediction_shape = images.predictionMultipleinput_3(dummymodel, [test_data_m3[0][0]], 1, configs[\"L8SR_S1_as3\"])[0].shape\n",
        "    assert prediction_shape == (1,256,256,2)\n",
        "\n",
        "\n",
        "def test_load_data_correctly():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                  , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                  , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  result = images.LoadImage(flood_image_base, user_folder, kernel_buffer, conf, \"flood_half0\")\n",
        "  if type(result) == str:\n",
        "    assert result == \"image path doesn't exist\"\n",
        "  else:\n",
        "    imageDataset, patches, x_buffer, y_buffer, jsonFile = result\n",
        "    assert imageDataset.prefetch(1)._input_dataset.__class__.__name__ == \"BatchDataset\"\n",
        "    assert type(patches) == int\n",
        "    assert type(x_buffer) == int\n",
        "    assert type(y_buffer) == int\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_load_data_wrong_filename():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                  , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                  , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  result = images.LoadImage(flood_image_base, user_folder, kernel_buffer, conf, \"flood_half0s\")\n",
        "  if type(result) == str:\n",
        "    assert result == \"image path doesn't exist\"\n",
        "  else:\n",
        "    imageDataset, patches, x_buffer, y_buffer, jsonFile = result\n",
        "    assert imageDataset.prefetch(1)._input_dataset.__class__.__name__ == \"BatchDataset\"\n",
        "    assert type(patches) == int\n",
        "    assert type(x_buffer) == int\n",
        "    assert type(y_buffer) == int\n",
        "    assert type(jsonFile) == str\n",
        "def test_load_data_wrong_filename():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                  , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                  , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  result = images.LoadImage(flood_image_base, user_folder, kernel_buffer, conf, \"flood_half0s\")\n",
        "  if type(result) == str:\n",
        "    assert result == \"image path doesn't exist\"\n",
        "  else:\n",
        "    imageDataset, patches, x_buffer, y_buffer, jsonFile = result\n",
        "    assert imageDataset.prefetch(1)._input_dataset.__class__.__name__ == \"BatchDataset\"\n",
        "    assert type(patches) == int\n",
        "    assert type(x_buffer) == int\n",
        "    assert type(y_buffer) == int\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_load_data_wrong_filename():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                  , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                  , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  result = images.LoadImage(flood_image_base, user_folder, kernel_buffer, conf, \"flood_half0s\")\n",
        "  if type(result) == str:\n",
        "    assert result == \"image path doesn't exist\"\n",
        "  else:\n",
        "    imageDataset, patches, x_buffer, y_buffer, jsonFile = result\n",
        "    assert imageDataset.prefetch(1)._input_dataset.__class__.__name__ == \"BatchDataset\"\n",
        "    assert type(patches) == int\n",
        "    assert type(x_buffer) == int\n",
        "    assert type(y_buffer) == int\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_load_data_wrong_filename():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                  , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                  , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  result = images.LoadImage(flood_image_base, user_folder, kernel_buffer, conf, \"flood_half0s\")\n",
        "  if type(result) == str:\n",
        "    assert result == \"image path doesn't exist\"\n",
        "  else:\n",
        "    imageDataset, patches, x_buffer, y_buffer, jsonFile = result\n",
        "    assert imageDataset.prefetch(1)._input_dataset.__class__.__name__ == \"BatchDataset\"\n",
        "    assert type(patches) == int\n",
        "    assert type(x_buffer) == int\n",
        "    assert type(y_buffer) == int\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "\n",
        "def test_FS_Unet_bundle_wrong_file_location():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  conf = configs[\"L8SR\"]\n",
        "  preproc = preprocessing.Preprocessor(conf)\n",
        "  MODEL_DIR = 'gs://' + conf.BUCKET + \"/\" + conf.FOLDER + \"/Models/\" + conf.PROJECT_TITLE + \"_EPOCHS_10\"\n",
        "  model_custom = tf.keras.models.load_model(MODEL_DIR, custom_objects={'f1':metrics_.f1, \"dice_p_cc\": losses_.dice_p_cc})\n",
        "\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  prediction_output = images.doPrediction_multiview_2(flood_image_base, user_folder, \\\n",
        "                            kernel_buffer, model_custom, \"0\", conf, \"flood_halfasd\"+\"0\")\n",
        "  if type(prediction_output) == str:\n",
        "    assert \"wrong file location\"\n",
        "  else:\n",
        "    out_image_asset, out_image_file, jsonFile = prediction_output\n",
        "    assert type(out_image_asset) == str\n",
        "    assert type(out_image_file) == str\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "\n",
        "def test_Multiview2_bundle_wrong_file_location():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  preproc = preprocessing.Preprocessor(conf)\n",
        "  MODEL_DIR = 'gs://' + conf.BUCKET + \"/\" + conf.FOLDER + \"/Models/\" + conf.PROJECT_TITLE\n",
        "  model_custom = tf.keras.models.load_model(MODEL_DIR, custom_objects={'f1':metrics_.f1, \"dice_p_cc\": losses_.dice_p_cc})\n",
        "\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  prediction_output = images.doPrediction_multiview_2(flood_image_base, user_folder, \\\n",
        "                            kernel_buffer, model_custom, \"0\", conf, \"flood_halfasd\"+\"0\")\n",
        "  if type(prediction_output) == str:\n",
        "    assert \"wrong file location\"\n",
        "  else:\n",
        "    out_image_asset, out_image_file, jsonFile = prediction_output\n",
        "    assert type(out_image_asset) == str\n",
        "    assert type(out_image_file) == str\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_Multiview3_bundle_wrong_file_location():\n",
        "  conf = configs[\"L8SR_S1_as3\"]\n",
        "  preproc = preprocessing.Preprocessor(conf)\n",
        "  MODEL_DIR = 'gs://' + conf.BUCKET + \"/\" + conf.FOLDER + \"/Models/\" + conf.PROJECT_TITLE + \"_EPOCHS_10\"\n",
        "  model_custom = tf.keras.models.load_model(MODEL_DIR, custom_objects={'f1':metrics_.f1, \"dice_p_cc\": losses_.dice_p_cc})\n",
        "\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  prediction_output = images.doPrediction_multiview_3(flood_image_base, user_folder, \\\n",
        "                            kernel_buffer, model_custom, \"0\", conf, \"flood_halfasd\"+\"0\")\n",
        "  if type(prediction_output) == str:\n",
        "    assert \"wrong file location\"\n",
        "  else:\n",
        "    out_image_asset, out_image_file, jsonFile = prediction_output\n",
        "    assert type(out_image_asset) == str\n",
        "    assert type(out_image_file) == str\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_Multiview2_bundle():\n",
        "  TRAIN_SIZE = 1\n",
        "  EVAL_SIZE = 1\n",
        "  configs_multi_global={}\n",
        "  configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"] = config.configuration(\"L8SR_S1A_sl_CC_dp0.3\", BANDS1 = [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"], BANDS2=[\"VV\", \"VH\", \"angle\", \"slope\"]\\\n",
        "                                                , TRAIN_SIZE= TRAIN_SIZE, EVAL_SIZE = EVAL_SIZE\\\n",
        "                                                , EPOCHS=10, BATCH_SIZE = 16, dropout_prob=0.3, LOSS=losses.get(\"categorical_crossentropy\"), type_ = 2, country=\"TH\")\n",
        "  conf = configs_multi_global[\"L8SR_S1A_sl_CC_dp0.3\"]\n",
        "  preproc = preprocessing.Preprocessor(conf)\n",
        "  MODEL_DIR = 'gs://' + conf.BUCKET + \"/\" + conf.FOLDER + \"/Models/\" + conf.PROJECT_TITLE\n",
        "  model_custom = tf.keras.models.load_model(MODEL_DIR, custom_objects={'f1':metrics_.f1, \"dice_p_cc\": losses_.dice_p_cc})\n",
        "\n",
        "  kernel_buffer = [128, 128]\n",
        "  user_folder = 'users/mewchayutaphong'\n",
        "  flood_image_base = f'flood_thai_with_Multi_floodEXP_half_'\n",
        "  prediction_output = images.doPrediction_multiview_2(flood_image_base, user_folder, \\\n",
        "                            kernel_buffer, model_custom, \"0\", conf, \"flood_half\"+\"0\")\n",
        "  if type(prediction_output) == str:\n",
        "    assert \"wrong file location\"\n",
        "  else:\n",
        "    out_image_asset, out_image_file, jsonFile = prediction_output\n",
        "    assert type(out_image_asset) == str\n",
        "    assert type(out_image_file) == str\n",
        "    assert type(jsonFile) == str\n",
        "\n",
        "def test_wrong_bucket_image():\n",
        "    conf = configs[\"L8SR_S1_as3\"]\n",
        "    conf.BUCKET = \"asd\"\n",
        "    foldername = \"wrongbucket\"\n",
        "    n = 1 # Number of shards in each polygon.\n",
        "    N = 1 # Total sample size in each polygon.\n",
        "    images.doExport(tb_image_base, kernel_buffer, tb_region, conf, \"sometext\")\n",
        "    while ee.data.listOperations()[0]['metadata']['state'] == 'PENDING':\n",
        "      time.sleep(3)\n",
        "    if ee.data.listOperations()[2]['metadata']['state'] == 'COMPLETED':\n",
        "      message = 'Image export completed.'\n",
        "    elif ee.data.listOperations()[2]['metadata']['state'] == 'FAILED':\n",
        "      message = 'Error with image export.'\n",
        "    print(message)\n",
        "    assert message == 'Error with image export.'\n",
        "    # assert message == 'Image export completed.'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpeNX4REteM"
      },
      "source": [
        "## Compilation\n",
        "Please run the below cell to test all the files created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxqwNobxPjs9",
        "outputId": "2285d34e-e287-49ca-86a3-1d663945597e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_metrics.py\u001b[0m \u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m                                            \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\n",
            "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
            "test_metrics.py::test_Metrics[data0-1]\n",
            "  /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "    _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "test_metrics.py::test_Metrics_2[data_m20-1]\n",
            "  /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "    _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "test_metrics.py::test_Metrics_3[data_m30-1]\n",
            "  /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "    _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "test_metrics.py::test_Metrics_2_hp[data_m2_hp0-1]\n",
            "  /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "    _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "-- Docs: http://doc.pytest.org/en/latest/warnings.html\n",
            "\n",
            "Results (21.01s):\n",
            "\u001b[32m       4 passed\u001b[0m\n",
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_preprocessing.py\u001b[0m \u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m                                    \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\n",
            "\n",
            "Results (6.16s):\n",
            "\u001b[32m       6 passed\u001b[0m\n",
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_model.py\u001b[0m \u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m                                              \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\n",
            "\n",
            "Results (19.57s):\n",
            "\u001b[32m       4 passed\u001b[0m\n",
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_losses_.py\u001b[0m \u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m                                              \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m████\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m████\u001b[0m\n",
            "\n",
            "Results (3.42s):\n",
            "\u001b[32m       2 passed\u001b[0m\n",
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_sampling.py\u001b[0m \u001b[32m✓\u001b[0m                                              \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█████████\u001b[0m\n",
            "\n",
            "Results (19.94s):\n",
            "\u001b[32m       1 passed\u001b[0m\n",
            "\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.5\n",
            "\n",
            " \u001b[36m\u001b[0mtest_images.py\u001b[0m \u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m\u001b[32m✓\u001b[0m                                       \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\n",
            "\n",
            "Results (374.43s):\n",
            "\u001b[32m      10 passed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m pytest test_metrics.py \n",
        "!python -m pytest test_preprocessing.py\n",
        "!python -m pytest test_model.py\n",
        "!python -m pytest test_losses_.py\n",
        "!python -m pytest test_sampling.py\n",
        "!python -m pytest test_images.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWMkw06iDBGt"
      },
      "source": [
        "Config, metrics_, losses_ is tested in more details with automatic testing in github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc3SrFmUTl2Q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "pytest.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}